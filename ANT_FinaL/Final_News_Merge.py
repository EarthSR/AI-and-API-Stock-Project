import os
import pandas as pd
from datetime import datetime
import sys

# âœ… à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ UnicodeEncodeError (à¸‚à¹‰à¸²à¸¡à¸­à¸µà¹‚à¸¡à¸ˆà¸´à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š)
sys.stdout.reconfigure(encoding="utf-8", errors="ignore")

def clean_and_process_data(input_folder, output_file):
    all_data = []
    csv_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith('.csv')]

    if not csv_files:
        print(f"âŒ à¹„à¸¡à¹ˆà¸à¸šà¹„à¸Ÿà¸¥à¹Œ CSV à¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ {input_folder}")
        return

    for file in csv_files:
        try:
            df = pd.read_csv(file, encoding='utf-8')
            df['Source'] = df['link'].apply(lambda x: 'Investing' if 'investing.com' in str(x) else 'BangkokPost' if 'bangkokpost.com' in str(x) else 'Unknown')
            all_data.append(df)
        except Exception as e:
            print(f"âš ï¸ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ {file}: {e}")
            continue

    df = pd.concat(all_data, ignore_index=True)

    print(f"\nğŸ” [DEBUG] à¸„à¹ˆà¸²à¸‚à¸­à¸‡ 'Source' à¸«à¸¥à¸±à¸‡à¸£à¸§à¸¡à¹„à¸Ÿà¸¥à¹Œ {input_folder}:")
    print(df['Source'].value_counts(dropna=False))

    df_cleaned = df.drop_duplicates(subset=['title', 'link'], keep='first')

    # ğŸ”¹ à¸›à¸£à¸±à¸šà¸£à¸¹à¸›à¹à¸šà¸šà¸§à¸±à¸™à¸—à¸µà¹ˆ
    df_cleaned.loc[:, 'date'] = pd.to_datetime(df_cleaned['date'], errors='coerce')
    df_cleaned = df_cleaned.dropna(subset=['date'])

    # ğŸ”¹ **à¸¥à¸šà¸‚à¹ˆà¸²à¸§à¸—à¸µà¹ˆà¹€à¸à¹ˆà¸²à¸à¸§à¹ˆà¸² 01/01/2018**
    cutoff_date = datetime(2018, 1, 1)
    df_cleaned = df_cleaned[df_cleaned['date'] >= cutoff_date]

    print(f"\nğŸ” [DEBUG] à¸„à¹ˆà¸²à¸‚à¸­à¸‡ 'Source' à¸à¹ˆà¸­à¸™à¸šà¸±à¸™à¸—à¸¶à¸ {output_file}:")
    print(df_cleaned['Source'].value_counts(dropna=False))

    df_cleaned.to_csv(output_file, index=False, encoding='utf-8')
    print(f"âœ… [CLEANED] à¹„à¸Ÿà¸¥à¹Œà¸–à¸¹à¸à¸šà¸±à¸™à¸—à¸¶à¸à¸—à¸µà¹ˆ: {output_file}\n")

def delete_csv_files_in_folder(folder_path, exclude_filename):
    csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv') and f != os.path.basename(exclude_filename)]
    for file in csv_files:
        try:
            os.remove(file)
            print(f"ğŸ—‘ï¸ à¸¥à¸šà¹„à¸Ÿà¸¥à¹Œ: {file}")
        except Exception as e:
            print(f"âš ï¸ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸¥à¸šà¹„à¸Ÿà¸¥à¹Œ {file}: {e}")

# ğŸ”¹ à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ
bangkokpost_folder = 'D:\\Stock_Project\\AI-and-API-Stock-Project\\BangkokPost_Folder'
investing_folder = 'D:\\Stock_Project\\AI-and-API-Stock-Project\\Investing_Folder'
news_data_folder = 'D:\\Stock_Project\\AI-and-API-Stock-Project\\news_data'

bangkokpost_output_file = os.path.join(news_data_folder, 'Thai_News.csv')
investing_output_file = os.path.join(news_data_folder, 'USA_News.csv')
final_output_file = os.path.join(news_data_folder, 'Final_News.csv')

# ğŸ”¹ à¸¥à¸š Final_News.csv à¸à¹ˆà¸­à¸™à¹€à¸£à¸´à¹ˆà¸¡
if os.path.exists(final_output_file):
    os.remove(final_output_file)
    print("ğŸ—‘ï¸ à¸¥à¸š Final_News.csv à¹€à¸à¹ˆà¸²à¸à¹ˆà¸­à¸™à¸£à¸§à¸¡à¹ƒà¸«à¸¡à¹ˆ")

# ğŸ”¹ à¸£à¸§à¸¡à¹à¸¥à¸°à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¹„à¸Ÿà¸¥à¹Œà¸‚à¹ˆà¸²à¸§
clean_and_process_data(bangkokpost_folder, bangkokpost_output_file)
clean_and_process_data(investing_folder, investing_output_file)

# ğŸ”¹ Debug à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™ news_data à¸à¹ˆà¸­à¸™à¸£à¸§à¸¡
print("\nğŸ” [DEBUG] à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œ news_data à¸à¹ˆà¸­à¸™à¸£à¸§à¸¡:")
print(os.listdir(news_data_folder))

# ğŸ”¹ à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™ news_data
final_dataframes = []
for file in os.listdir(news_data_folder):
    if file.endswith('.csv'):
        file_path = os.path.join(news_data_folder, file)
        df_temp = pd.read_csv(file_path, encoding='utf-8')

        print(f"\nğŸ” [DEBUG] à¸„à¹ˆà¸²à¸‚à¸­à¸‡ 'Source' à¹ƒà¸™ {file}:")
        print(df_temp['Source'].value_counts(dropna=False))

        final_dataframes.append(df_temp)

df_final = pd.concat(final_dataframes, ignore_index=True)

# ğŸ”¹ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¹ˆà¸²à¸‹à¹‰à¸³à¸à¹ˆà¸­à¸™à¸šà¸±à¸™à¸—à¸¶à¸
df_final = df_final.drop_duplicates(subset=['title', 'link'], keep='first')

# ğŸ”¹ **à¸¥à¸šà¸‚à¹ˆà¸²à¸§à¸—à¸µà¹ˆà¹€à¸à¹ˆà¸²à¸à¸§à¹ˆà¸² 01/01/2018** à¹ƒà¸™ Final_News.csv
cutoff_date = datetime(2018, 1, 1)  # âœ… à¹à¸à¹‰à¹„à¸‚à¸•à¸£à¸‡à¸™à¸µà¹‰
df_final['date'] = pd.to_datetime(df_final['date'], errors='coerce')
df_final = df_final.dropna(subset=['date'])
df_final = df_final[df_final['date'] >= cutoff_date]

print("\nğŸ” [DEBUG] à¸„à¹ˆà¸²à¸‚à¸­à¸‡ 'Source' à¸«à¸¥à¸±à¸‡à¸£à¸§à¸¡à¹„à¸Ÿà¸¥à¹Œ news_data:")
print(df_final['Source'].value_counts(dropna=False))

# ğŸ”¹ **à¸ªà¸£à¸¸à¸›à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹ˆà¸²à¸§à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹à¸«à¸¥à¹ˆà¸‡à¹à¸¥à¸°à¸£à¸§à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”**
total_bangkokpost = df_final[df_final['Source'] == 'BangkokPost'].shape[0]
total_investing = df_final[df_final['Source'] == 'Investing'].shape[0]
total_news = df_final.shape[0]

print("\nğŸ“Š [SUMMARY REPORT]")
print(f"âœ… BangkokPost: {total_bangkokpost} à¸‚à¹ˆà¸²à¸§")
print(f"âœ… Investing: {total_investing} à¸‚à¹ˆà¸²à¸§")
print(f"âœ… à¸£à¸§à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {total_news} à¸‚à¹ˆà¸²à¸§")

df_final.to_csv(final_output_file, index=False, encoding='utf-8')

# ğŸ”¹ à¸¥à¸šà¹„à¸Ÿà¸¥à¹Œ CSV à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰
delete_csv_files_in_folder(news_data_folder, final_output_file)

print("\nğŸ¯ [DONE] à¸à¸²à¸£à¸£à¸§à¸¡à¹à¸¥à¸°à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ!")
