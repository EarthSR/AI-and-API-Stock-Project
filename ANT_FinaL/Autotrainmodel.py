import numpy as np
import pandas as pd
import pymysql
import joblib
import pandas_ta as ta
from sqlalchemy import create_engine
from sklearn.preprocessing import LabelEncoder

# ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MySQL ‡∏î‡πâ‡∏ß‡∏¢ SQLAlchemy
db_connection_str = "mysql+pymysql://trademine:trade789@10.10.50.62/TradeMine"
engine = create_engine(db_connection_str)

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î Scaler ‡πÅ‡∏•‡∏∞ Encoder
scaler_features = joblib.load("../LSTM_model/scaler_features.pkl")
scaler_target = joblib.load("../LSTM_model/scaler_target.pkl")
ticker_encoder = joblib.load("../LSTM_model/ticker_encoder.pkl")

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î Weighted Stacking Model
weighted_stacking_price = joblib.load("../Ensemble_Model/weighted_stacking_price.pkl")
weighted_stacking_direction = joblib.load("../Ensemble_Model/weighted_stacking_direction.pkl")

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î Base Models (XGBoost ‡πÅ‡∏•‡∏∞ RandomForest)
xgb_model = joblib.load("../Ensemble_Model/xgb_model_price.pkl")
rf_model = joblib.load("../Ensemble_Model/rf_model_price.pkl")
xgb_dir_model = joblib.load("../Ensemble_Model/xgb_model_direction.pkl")
rf_dir_model = joblib.load("../Ensemble_Model/rf_model_direction.pkl")

def calculate_indicators(df):
    """ üìå ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Indicators ‡πÉ‡∏ô Python """
    df = df.copy()

    print(f"üìä ‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Indicator ({df.shape[0]} rows)")

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RSI
    df["RSI"] = ta.rsi(df["ClosePrice"], length=14)

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì EMA
    df["EMA_10"] = ta.ema(df["ClosePrice"], length=10)
    df["EMA_20"] = ta.ema(df["ClosePrice"], length=20)

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì SMA
    df["SMA_50"] = ta.sma(df["ClosePrice"], length=50)
    df["SMA_200"] = ta.sma(df["ClosePrice"], length=200)

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MACD
    macd = ta.macd(df["ClosePrice"])
    df["MACD"] = macd["MACD_12_26_9"] if macd is not None else np.nan
    df["MACD_Signal"] = macd["MACDs_12_26_9"] if macd is not None else np.nan

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Bollinger Bands
    bb = ta.bbands(df["ClosePrice"], length=20)
    df["Bollinger_High"] = bb["BBU_20_2.0"] if bb is not None else np.nan
    df["Bollinger_Low"] = bb["BBL_20_2.0"] if bb is not None else np.nan

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ATR
    df["ATR"] = ta.atr(df["HighPrice"], df["LowPrice"], df["ClosePrice"], length=14)

    print(f"üìä ‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Indicator ({df.shape[0]} rows)")

    return df.fillna(method="bfill").reset_index(drop=True)

def safe_transform(encoder, ticker):
    """ üìå ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤ `Ticker` ‡πÄ‡∏õ‡πá‡∏ô ID ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô -1 """
    if ticker in encoder.classes_:
        return encoder.transform([ticker])[0]
    else:
        print(f"‚ö†Ô∏è ‡∏´‡∏∏‡πâ‡∏ô {ticker} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô `ticker_encoder`")
        return -1

def walk_forward_validation_multi_task(engine, scaler_features, scaler_target, ticker_encoder, seq_length=10):
    """ üìå ‡∏ó‡∏≥ Walk-Forward Validation ‡πÉ‡∏ä‡πâ Weighted Stacking Model """
    all_predictions = []

    # ‚úÖ ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏´‡∏∏‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    query_tickers = "SELECT DISTINCT StockSymbol FROM Stock"
    tickers_df = pd.read_sql(query_tickers, engine)
    tickers = tickers_df["StockSymbol"].dropna().unique().tolist()

    for ticker in tickers:
        print(f"\nüìà Processing Ticker: {ticker}")

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤ ticker
        if not isinstance(ticker, str) or ticker.strip() == "":
            print(f"‚ö†Ô∏è ‡∏Ñ‡πà‡∏≤ `StockSymbol` ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ({ticker}) ‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏∏‡πâ‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏õ...")
            continue

        ticker_id_val = safe_transform(ticker_encoder, ticker)
        if ticker_id_val == -1:
            continue

        # ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô** (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Indicator)
        query_stock = f"""
            SELECT Date, OpenPrice, HighPrice, LowPrice, ClosePrice, Volume, 
                Changepercen, TotalRevenue, QoQGrowth, EPS, ROE, NetProfitMargin, 
                DebtToEquity, PERatio, Dividend_Yield 
            FROM StockDetail 
            WHERE StockSymbol = '{ticker}' 
            ORDER BY Date DESC 
            LIMIT {seq_length + 300}
        """
        df_ticker = pd.read_sql(query_stock, engine)
        print(f"üîç {ticker}: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å SQL ‡∏Å‡πà‡∏≠‡∏ô Indicator: {df_ticker.shape}")  # Debug


        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤
        if df_ticker.empty or len(df_ticker) < seq_length:
            print(f"‚ö†Ô∏è Not enough data for {ticker}, skipping...")
            continue

        df_ticker = df_ticker.sort_values("Date").reset_index(drop=True)

        # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Indicators ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏°‡∏≤‡∏Å‡∏û‡∏≠
        df_ticker = calculate_indicators(df_ticker)

        # ‚úÖ ‡πÉ‡∏ä‡πâ **‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 10 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        df_ticker = df_ticker.iloc[-seq_length:]

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 ‡∏ß‡∏±‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏°‡∏µ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å Indicator ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if df_ticker.isnull().sum().sum() > 0:
            print(f"‚ö†Ô∏è Missing values in indicators for {ticker}, skipping...")
            continue

        feature_columns = df_ticker.columns.tolist()
        features = df_ticker[feature_columns].values
        ticker_ids = np.full((seq_length,), ticker_id_val)

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Indicators
        if df_ticker.empty or len(df_ticker) < seq_length:
            print(f"‚ö†Ô∏è Not enough data after Indicator Calculation for {ticker}, skipping...")
            continue

        # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
        historical_data = df_ticker.iloc[-seq_length:]
        features = historical_data[feature_columns].values

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ features ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
        if features.shape[0] == 0:
            print(f"‚ö†Ô∏è Features array is empty for {ticker}, skipping...")
            continue

        ticker_ids = np.full((seq_length,), ticker_id_val)

        # ‚úÖ ‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Feature ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
        features_scaled = scaler_features.transform(features.reshape(-1, len(feature_columns)))
        X_features = features_scaled.reshape(1, seq_length, len(feature_columns))
        X_ticker = ticker_ids.reshape(1, seq_length)


        # ‚úÖ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢ Base Models
        pred_price_xgb = xgb_model.predict(X_features.reshape(1, -1))[0]
        pred_price_rf = rf_model.predict(X_features.reshape(1, -1))[0]

        # ‚úÖ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢ Base Models
        pred_dir_xgb = xgb_dir_model.predict(X_features.reshape(1, -1))[0]
        pred_dir_rf = rf_dir_model.predict(X_features.reshape(1, -1))[0]

        # ‚úÖ ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏≤‡∏Å Scaler
        pred_price_xgb_actual = scaler_target.inverse_transform([[pred_price_xgb]])[0][0]
        pred_price_rf_actual = scaler_target.inverse_transform([[pred_price_rf]])[0][0]

        # ‚úÖ ‡πÉ‡∏ä‡πâ Weighted Stacking
        w_xgb, w_rf = 0.5, 0.5
        predicted_price = (w_xgb * pred_price_xgb_actual) + (w_rf * pred_price_rf_actual)
        predicted_dir = 1 if ((0.5 * pred_dir_xgb) + (0.5 * pred_dir_rf)) >= 0.5 else 0

        future_date = pd.to_datetime(df_ticker.iloc[-1]["Date"]) + pd.DateOffset(1)

        print(f"‚úÖ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà {future_date}: Predicted Price: {predicted_price:.2f}, Direction: {'Up' if predicted_dir == 1 else 'Down'}")

        all_predictions.append({'Ticker': ticker, 'Date': future_date, 'Predicted_Price': predicted_price, 'Predicted_Dir': predicted_dir})

    print("\n‚úÖ ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")
    return pd.DataFrame(all_predictions)


predictions_df = walk_forward_validation_multi_task(engine, scaler_features, scaler_target, ticker_encoder, seq_length=10)
predictions_df.to_csv("weighted_stacking_predictions.csv", index=False)
print("\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå 'weighted_stacking_predictions.csv' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
