import yfinance as yf
import pandas as pd
import datetime
import sys
import os
from dotenv import load_dotenv
import io
from pandas_market_calendars import get_calendar
try:
    import mysql.connector
except ImportError:
    print("‚ö†Ô∏è mysql-connector-python not installed. Skipping database operations.")
    mysql = None

# ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô UnicodeEncodeError
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
CURRENT_DIR = os.getcwd()
path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'config.env')
load_dotenv(path)

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
def check_table_structure():
    if not mysql:
        return False
    try:
        conn = mysql.connector.connect(
            host=DB_HOST,
            user=DB_USER,
            password=DB_PASSWORD,
            database=DB_NAME
        )
        cursor = conn.cursor()
        cursor.execute("SHOW COLUMNS FROM StockDetail")
        columns = [col[0] for col in cursor.fetchall()]
        cursor.close()
        conn.close()
        expected_columns = ['Date', 'StockSymbol']
        missing_columns = [col for col in expected_columns if col not in columns]
        if missing_columns:
            print(f"‚ùå Missing columns in StockDetail: {missing_columns}")
            print("‚ö†Ô∏è Using default start date (2024-01-01) due to table issues.")
            return False
        print("‚úÖ Table structure is sufficient for date checking")
        return True
    except Exception as e:
        print(f"‚ùå Error checking table structure: {e}")
        print("‚ö†Ô∏è Using default start date (2024-01-01) due to table issues.")
        return False

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Mock)
latest_dates = {}
tickers = ['AAPL', 'NVDA', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'AVGO', 'TSM', 'AMD']
has_valid_table = False
today = datetime.datetime.now()
current_date = (today - datetime.timedelta(days=1)).strftime('%Y-%m-%d')  # 13 ‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏° 2025

# ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Mock (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
MOCK_MODE = False  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô True ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö
if MOCK_MODE:
    latest_dates = {ticker: "2025-07-11" for ticker in tickers}  # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
else:
    if all([DB_HOST, DB_USER, DB_PASSWORD, DB_NAME]) and mysql:
        try:
            conn = mysql.connector.connect(
                host=DB_HOST,
                user=DB_USER,
                password=DB_PASSWORD,
                database=DB_NAME,
                autocommit=True
            )
            cursor = conn.cursor()
            print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
            has_valid_table = check_table_structure()
            
            if has_valid_table:
                for ticker in tickers:
                    try:
                        cursor.execute("SELECT MAX(Date) FROM StockDetail WHERE StockSymbol = %s", (ticker,))
                        result = cursor.fetchone()[0]
                        if result is None:
                            latest_dates[ticker] = "2024-01-01"
                        elif result > today.date():
                            print(f"‚ö†Ô∏è Future date found for {ticker}: {result}. Using default start date (2024-01-01)")
                            latest_dates[ticker] = "2024-01-01"
                        else:
                            latest_dates[ticker] = (result + datetime.timedelta(days=1)).strftime('%Y-%m-%d')
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error fetching latest date for {ticker}: {e}")
                        latest_dates[ticker] = "2024-01-01"
            else:
                for ticker in tickers:
                    latest_dates[ticker] = "2024-01-01"
            
            cursor.close()
            conn.close()
            print("üîπ ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß")
        except Exception as e:
            print(f"‚ùå Failed to connect to database: {e}")
            for ticker in tickers:
                latest_dates[ticker] = "2024-01-01"
    else:
        print("‚ö†Ô∏è Missing database configuration or mysql-connector-python, using default start date (2024-01-01)")
        for ticker in tickers:
            latest_dates[ticker] = "2024-01-01"

# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î
start_date_db = min(latest_dates.values())
start_date = min(latest_dates.values())  # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print(f"üîπ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {start_date}")
end_date = current_date  # 13 ‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏° 2025
print(f"üîπ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {end_date}")

# ‡∏õ‡∏£‡∏±‡∏ö start_date ‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 10 ‡∏ß‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô end_date
start_date = (pd.to_datetime(start_date) - datetime.timedelta(days=10)).strftime('%Y-%m-%d')
if pd.to_datetime(start_date) > pd.to_datetime(end_date):
    start_date = (pd.to_datetime(end_date) - datetime.timedelta(days=10)).strftime('%Y-%m-%d')
    if pd.to_datetime(start_date) < pd.to_datetime("2024-01-01"):
        start_date = "2024-01-01"

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if start_date >= end_date:
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á (start_date: {start_date} >= end_date: {end_date})")
    sys.exit(0)

print(f"üîπ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô NYSE ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢
nyse = get_calendar('NYSE')
trading_days = nyse.schedule(start_date=start_date, end_date=end_date).index

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
def is_trading_day(date, trading_days):
    return pd.Timestamp(date) in trading_days

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢ Forward Fill ‡πÅ‡∏•‡∏∞ Rolling Mean
def impute_holiday_data(ticker_data, all_dates, ticker, window=3):
    ticker_data = ticker_data.copy()
    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
    if not all(col in ticker_data.columns for col in required_columns):
        print(f"‚ùå Missing required columns for {ticker}: {required_columns}")
        return pd.DataFrame()
    
    ticker_data.index = pd.to_datetime(ticker_data.index).tz_localize(None)
    ticker_data = ticker_data.reindex(all_dates, method=None)
    
    missing_percentage = ticker_data[required_columns].isnull().mean() * 100
    print(f"üîç Missing data for {ticker}: {missing_percentage.to_dict()}")
    if missing_percentage.sum() > 20:
        print(f"‚ö†Ô∏è Warning: Excessive missing data for {ticker} ({missing_percentage.sum():.2f}%).")

    ticker_data[['Open', 'High', 'Low', 'Close']] = (
        ticker_data[['Open', 'High', 'Low', 'Close']]
        .ffill(limit=2)
        .bfill(limit=2)
        .rolling(window=window, min_periods=1).mean()
    )
    ticker_data['Volume'] = ticker_data['Volume'].fillna(0)
    ticker_data['Changepercent'] = (ticker_data['Close'] - ticker_data['Open']) / ticker_data['Open'] * 100
    ticker_data['Changepercent'] = ticker_data['Changepercent'].fillna(0)

    return ticker_data

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î)
all_dates = pd.date_range(start=start_date, end=end_date, freq='D')

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ yfinance
max_retries = 3
data_dict = {}

for ticker in tickers:
    retry_count = 0
    while retry_count < max_retries:
        try:
            stock = yf.Ticker(ticker)
            ticker_data = stock.history(start=start_date, end=end_date, interval='1d')
            if not ticker_data.empty:
                print(f"‚úÖ Retrieved data for {ticker}: {len(ticker_data)} rows")
                print(f"üìã Sample data for {ticker}:\n{ticker_data.head()}")
                ticker_data = impute_holiday_data(ticker_data, all_dates, ticker, window=3)
                ticker_data['Ticker'] = ticker
                data_dict[ticker] = ticker_data
            else:
                print(f"‚ö†Ô∏è No data retrieved for {ticker}")
            break
        except Exception as e:
            retry_count += 1
            print(f"‚ö†Ô∏è Error for {ticker}: {e} (‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà {retry_count}/{max_retries})")
            if retry_count == max_retries:
                print(f"‚ùå Failed to retrieve data for {ticker} after {max_retries} attempts")
                break

if not data_dict:
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å yfinance")
    sys.exit(0)

# ‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
data_list = []
for ticker, ticker_data in data_dict.items():
    if ticker_data.empty:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker}")
        continue
    for date in ticker_data.index:
        if not is_trading_day(date, trading_days):
            print(f"‚ö†Ô∏è Note: Data for {ticker} on {date.strftime('%Y-%m-%d')} is imputed using Rolling Mean.")
    data_list.append(ticker_data)

if not data_list:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏î ‡πÜ ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ")
    sys.exit(1)

# ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
cleaned_data = pd.concat(data_list).reset_index()

# ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö CSV
cleaned_data = cleaned_data.rename(columns={
    'index': 'Date',
    'Ticker': 'Ticker',
    'Open': 'Open',
    'High': 'High',
    'Low': 'Low',
    'Close': 'Close',
    'Volume': 'Volume',
    'Changepercent': 'Changepercent'
})

cleaned_data['Date'] = pd.to_datetime(cleaned_data['Date']).dt.strftime('%Y-%m-%d')

# ‚úÖ ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
columns_to_keep = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume', 'Changepercent']
cleaned_data = cleaned_data[columns_to_keep]

# ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
print("üîπ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏≠‡∏Å...")
before_filter = len(cleaned_data)
cleaned_data = cleaned_data[
    (cleaned_data['Open'].notna()) &
    (cleaned_data['High'].notna()) &
    (cleaned_data['Low'].notna()) &
    (cleaned_data['Close'].notna()) &
    (cleaned_data['Date'] >= start_date_db) &    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ô‡∏µ‡πâ
    (cleaned_data['Date'] <= end_date)
]
after_filter = len(cleaned_data)
print(f"üîπ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß: {before_filter} -> {after_filter} ‡πÅ‡∏ñ‡∏ß")

# ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
cleaned_data = cleaned_data.sort_values(['Date', 'Ticker']).reset_index(drop=True)
cleaned_data = cleaned_data.drop_duplicates(subset=['Date', 'Ticker'], keep='first')

# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV
output_path = os.path.join(os.path.dirname(__file__), "Stock", "stock_data_usa.csv")
cleaned_data.to_csv(output_path, index=False)
print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå CSV ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {output_path}")

# ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print(f"üîπ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(cleaned_data)} ‡πÅ‡∏ñ‡∏ß")
print(f"üîπ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {cleaned_data['Date'].nunique()} ‡∏ß‡∏±‡∏ô")
if not cleaned_data.empty:
    print(f"üîπ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {cleaned_data['Date'].min()} ‡∏ñ‡∏∂‡∏á {cleaned_data['Date'].max()}")
    for ticker in cleaned_data['Ticker'].unique():
        ticker_data = cleaned_data[cleaned_data['Ticker'] == ticker]
        print(f"üîπ {ticker}: {len(ticker_data)} ‡πÅ‡∏ñ‡∏ß, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î {ticker_data['Date'].max()}")
    print("\nüìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    print(cleaned_data.head(10))
else:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")