import numpy as np
import pandas as pd
import sqlalchemy
import os
import tensorflow as tf
import ta
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, RobustScaler, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score
import joblib
import warnings
from datetime import datetime, timedelta
import mysql.connector
from dotenv import load_dotenv
from tensorflow.keras.optimizers import Adam
from sqlalchemy import text

# XGBoost imports
import xgboost as xgb
from sklearn.impute import SimpleImputer
from ta.momentum import RSIIndicator
from ta.trend import SMAIndicator, MACD
from ta.volatility import BollingerBands, AverageTrueRange

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

# ======================== ENHANCED XGBoost Meta-Learner Class ========================
class XGBoostMetaLearner:
    """
    XGBoost Meta-Learner ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏ß‡∏° predictions ‡∏à‡∏≤‡∏Å LSTM ‡πÅ‡∏•‡∏∞ GRU
    ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏î‡πâ‡∏ß‡∏¢ technical indicators ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
    """
    
    def __init__(self, 
                 clf_model_path='../Ensemble_Model/xgb_classifier_model.pkl', 
                 reg_model_path='../Ensemble_Model/xgb_regressor_model.pkl',
                 scaler_dir_path='../Ensemble_Model/scaler_dir.pkl', 
                 scaler_price_path='../Ensemble_Model/scaler_price.pkl',
                 retrain_frequency=5):
        
        self.clf_model_path = clf_model_path
        self.reg_model_path = reg_model_path
        self.scaler_dir_path = scaler_dir_path
        self.scaler_price_path = scaler_price_path
        self.retrain_frequency = retrain_frequency
        
        self.xgb_clf = None
        self.xgb_reg = None
        self.scaler_dir = None
        self.scaler_price = None
        
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        self.load_models()
    
    def load_models(self):
        """‡πÇ‡∏´‡∏•‡∏î XGBoost models ‡πÅ‡∏•‡∏∞ scalers"""
        try:
            if os.path.exists(self.clf_model_path):
                self.xgb_clf = joblib.load(self.clf_model_path)
                print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î XGBoost Classifier ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå XGBoost Classifier")
            
            if os.path.exists(self.reg_model_path):
                self.xgb_reg = joblib.load(self.reg_model_path)
                print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î XGBoost Regressor ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå XGBoost Regressor")
            
            if os.path.exists(self.scaler_dir_path):
                self.scaler_dir = joblib.load(self.scaler_dir_path)
                print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î Direction Scaler ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Direction Scaler")
                
            if os.path.exists(self.scaler_price_path):
                self.scaler_price = joblib.load(self.scaler_price_path)
                print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î Price Scaler ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            else:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Price Scaler")
                
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
    
    def calculate_technical_indicators(self, df):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì technical indicators ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost"""
        
        def calculate_for_ticker(group):
            if len(group) < 26:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 26 ‡∏ß‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MACD
                return group
            
            try:
                # RSI
                group['RSI'] = RSIIndicator(close=group['Close'], window=14).rsi()
                
                # SMA
                group['SMA_20'] = SMAIndicator(close=group['Close'], window=20).sma_indicator()
                
                # MACD
                macd = MACD(close=group['Close'])
                group['MACD'] = macd.macd()
                
                # Bollinger Bands
                bb = BollingerBands(close=group['Close'], window=20)
                group['BB_High'] = bb.bollinger_hband()
                group['BB_Low'] = bb.bollinger_lband()
                
                # ATR (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ High, Low columns)
                if 'High' in group.columns and 'Low' in group.columns:
                    atr = AverageTrueRange(high=group['High'], low=group['Low'], 
                                         close=group['Close'], window=14)
                    group['ATR'] = atr.average_true_range()
                else:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á High, Low ‡∏à‡∏≤‡∏Å Close ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
                    group['High'] = group['Close'] * 1.01
                    group['Low'] = group['Close'] * 0.99
                    atr = AverageTrueRange(high=group['High'], low=group['Low'], 
                                         close=group['Close'], window=14)
                    group['ATR'] = atr.average_true_range()
            
            except Exception as e:
                print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì technical indicators: {e}")
            
            return group
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° ticker - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç DeprecationWarning
        df_with_indicators = df.groupby('StockSymbol', group_keys=False).apply(calculate_for_ticker)
        df_with_indicators = df_with_indicators.reset_index(drop=True)
        
        # Fill NaN values
        indicator_cols = ['RSI', 'SMA_20', 'MACD', 'BB_High', 'BB_Low', 'ATR']
        for col in indicator_cols:
            if col in df_with_indicators.columns:
                df_with_indicators[col] = df_with_indicators.groupby('StockSymbol')[col].ffill().bfill()
                df_with_indicators[col] = df_with_indicators[col].fillna(df_with_indicators[col].mean())
        
        return df_with_indicators
    
    def prepare_features(self, df):
        """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost"""
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì technical indicators
        df = self.calculate_technical_indicators(df)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á meta features
        df['Price_Diff'] = df['PredictionClose_LSTM'] - df['PredictionClose_GRU']
        df['Dir_Agreement'] = (df['PredictionTrend_LSTM'] == df['PredictionTrend_GRU']).astype(int)
        
        # Normalize actual price ‡∏ï‡∏≤‡∏° ticker
        df['Actual_Price_Normalized'] = df.groupby('StockSymbol')['Close'].transform(
            lambda x: (x - x.mean()) / x.std() if x.std() != 0 else 0
        )
        
        # Features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö direction prediction
        direction_features = [
            'PredictionTrend_LSTM', 'PredictionTrend_GRU', 'Dir_Agreement', 
            'RSI', 'SMA_20', 'MACD', 'BB_High', 'BB_Low', 'ATR'
        ]
        
        # Features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö price prediction
        price_features = [
            'PredictionClose_LSTM', 'PredictionClose_GRU', 'Price_Diff',
            'RSI', 'SMA_20', 'MACD', 'BB_High', 'BB_Low', 'ATR',
            'Actual_Price_Normalized'
        ]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        available_dir_features = [f for f in direction_features if f in df.columns]
        available_price_features = [f for f in price_features if f in df.columns]
        
        return df, available_dir_features, available_price_features
    
    def predict_meta(self, df):
        """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ XGBoost Meta-Learner"""
        
        if self.xgb_clf is None or self.xgb_reg is None:
            print("‚ùå XGBoost models ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ")
            return df
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features
        df_prepared, dir_features, price_features = self.prepare_features(df)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ predictions ‡∏à‡∏≤‡∏Å LSTM ‡πÅ‡∏•‡∏∞ GRU
        prediction_mask = (
            df_prepared['PredictionClose_LSTM'].notna() & 
            df_prepared['PredictionClose_GRU'].notna() &
            df_prepared['PredictionTrend_LSTM'].notna() & 
            df_prepared['PredictionTrend_GRU'].notna()
        )
        
        if not prediction_mask.any():
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• predictions ‡∏à‡∏≤‡∏Å LSTM/GRU")
            return df
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ predictions
        df_to_predict = df_prepared[prediction_mask].copy()
        
        if len(df_to_predict) == 0:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
            return df
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing values
        imputer = SimpleImputer(strategy='mean')
        
        try:
            # Direction prediction
            X_dir = df_to_predict[dir_features]
            X_dir_filled = imputer.fit_transform(X_dir)
            
            if self.scaler_dir is not None:
                X_dir_scaled = self.scaler_dir.transform(X_dir_filled)
            else:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ Direction Scaler, ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö")
                X_dir_scaled = X_dir_filled
            
            # Price prediction
            X_price = df_to_predict[price_features]
            X_price_filled = imputer.fit_transform(X_price)
            
            if self.scaler_price is not None:
                X_price_scaled = self.scaler_price.transform(X_price_filled)
            else:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ Price Scaler, ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö")
                X_price_scaled = X_price_filled
            
            # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
            # Direction prediction
            xgb_pred_dir = self.xgb_clf.predict(X_dir_scaled)
            xgb_pred_dir_proba = self.xgb_clf.predict_proba(X_dir_scaled)[:, 1]
            
            # Price prediction
            xgb_pred_price = self.xgb_reg.predict(X_price_scaled)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô DataFrame
            df_prepared.loc[prediction_mask, 'XGB_Predicted_Direction_Raw'] = xgb_pred_dir
            df_prepared.loc[prediction_mask, 'XGB_Predicted_Direction_Proba'] = xgb_pred_dir_proba
            df_prepared.loc[prediction_mask, 'XGB_Predicted_Price_Raw'] = xgb_pred_price
            
            # ‡πÉ‡∏ä‡πâ Direction ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô
            df_prepared.loc[prediction_mask, 'XGB_Predicted_Direction'] = xgb_pred_dir
            
            # ‡∏õ‡∏£‡∏±‡∏ö Price ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Direction ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ
            current_prices = df_to_predict['Close'].values
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì price adjustment ‡∏ï‡∏≤‡∏° direction
            price_adjustments = []
            for i, (current_price, pred_dir, raw_price) in enumerate(zip(current_prices, xgb_pred_dir, xgb_pred_price)):
                raw_change_pct = (raw_price - current_price) / current_price
                
                if pred_dir == 1:  # ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
                    if raw_price <= current_price:  # ‡πÅ‡∏ï‡πà‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏•‡∏á
                        # ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (0.5-2%)
                        adjusted_change = max(0.005, abs(raw_change_pct) * 0.5)
                        adjusted_price = current_price * (1 + adjusted_change)
                    else:
                        adjusted_price = raw_price  # ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏î‡∏¥‡∏°
                else:  # ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏•‡∏á
                    if raw_price >= current_price:  # ‡πÅ‡∏ï‡πà‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
                        # ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (0.5-2%)
                        adjusted_change = max(0.005, abs(raw_change_pct) * 0.5)
                        adjusted_price = current_price * (1 - adjusted_change)
                    else:
                        adjusted_price = raw_price  # ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏î‡∏¥‡∏°
                
                price_adjustments.append(adjusted_price)
            
            df_prepared.loc[prediction_mask, 'XGB_Predicted_Price'] = price_adjustments
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì confidence score
            df_prepared.loc[prediction_mask, 'XGB_Confidence'] = np.abs(xgb_pred_dir_proba - 0.5) * 2
            
            print(f"‚úÖ XGBoost Meta-Learner ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {prediction_mask.sum()} ‡πÅ‡∏ñ‡∏ß (Direction-focused)")
            
            print(f"‚úÖ XGBoost Meta-Learner ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {prediction_mask.sum()} ‡πÅ‡∏ñ‡∏ß")
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ XGBoost: {e}")
            import traceback
            traceback.print_exc()
            
        return df_prepared
    
    def should_retrain_meta(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£ retrain XGBoost ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        meta_last_trained_path = "meta_last_trained.txt"
        
        if not os.path.exists(meta_last_trained_path):
            return True
        
        try:
            with open(meta_last_trained_path, "r") as f:
                last_trained_str = f.read().strip()
            last_trained_date = datetime.strptime(last_trained_str, "%Y-%m-%d")
            
            days_since_last_train = (datetime.now() - last_trained_date).days
            return days_since_last_train >= self.retrain_frequency
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà retrain: {e}")
            return True

# ======================== ENHANCED PREDICTION SYSTEM ========================

# ‡πÇ‡∏´‡∏•‡∏î configuration ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö environment
print("üîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î configuration...")
path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.env')

if not os.path.exists(path):
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå config.env ‡∏ó‡∏µ‡πà {path}")
    print("üìù ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á config.env...")
    
    try:
        with open(path, 'w') as f:
            f.write("# Database Configuration\n")
            f.write("DB_USER=your_username\n")
            f.write("DB_PASSWORD=your_password\n")
            f.write("DB_HOST=localhost\n")
            f.write("DB_NAME=your_database\n")
        
        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á config.env ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà {path}")
        print("üìã ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")
        exit()
        
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå config.env ‡πÑ‡∏î‡πâ: {e}")
        print("üìù ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå config.env ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
        print("   DB_USER=your_username")
        print("   DB_PASSWORD=your_password") 
        print("   DB_HOST=your_host")
        print("   DB_NAME=your_database")
        exit()

load_dotenv(path)

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö environment variables
required_vars = ['DB_USER', 'DB_PASSWORD', 'DB_HOST', 'DB_NAME']
missing_vars = [var for var in required_vars if not os.getenv(var)]

if missing_vars:
    print(f"‚ùå ‡∏Ç‡∏≤‡∏î environment variables: {missing_vars}")
    exit()

try:
    DB_CONNECTION = f"mysql+mysqlconnector://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}/{os.getenv('DB_NAME')}"
    print("‚úÖ Database connection string ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
except Exception as e:
    print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á database connection: {e}")
    exit()

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏•‡∏≤‡∏î
current_hour = datetime.now().hour
# if 8 <= current_hour < 18:
#     print("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢ (SET)...")
#     market_filter = "Thailand"
# elif 19 <= current_hour or current_hour < 5:
#     print("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô‡∏≠‡πÄ‡∏°‡∏£‡∏¥‡∏Å‡∏≤ (NYSE & NASDAQ)...")
#     market_filter = "America"
# else:
#     print("‚ùå ‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡πÄ‡∏°‡∏£‡∏¥‡∏Å‡∏≤")
#     exit()
market_filter = "America"
MODEL_LSTM_PATH = "../LSTM_model/best_v6_plus_minimal_tuning_v2_final_model.keras"
MODEL_GRU_PATH = "../GRU_Model/best_v6_plus_minimal_tuning_v2_final_model.keras"
SEQ_LENGTH = 10
RETRAIN_FREQUENCY = 5

# Dynamic weight parameters
WEIGHT_DECAY = 0.95
MIN_WEIGHT = 0.1
MAX_WEIGHT = 0.9

# ‡∏™‡∏£‡πâ‡∏≤‡∏á XGBoost Meta-Learner
print("üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° XGBoost Meta-Learner...")
meta_learner = XGBoostMetaLearner()

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ XGBoost models
xgb_available = (meta_learner.xgb_clf is not None and 
                meta_learner.xgb_reg is not None and
                meta_learner.scaler_dir is not None and 
                meta_learner.scaler_price is not None)

if xgb_available:
    print("‚úÖ XGBoost Meta-Learner ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
else:
    print("‚ö†Ô∏è XGBoost Meta-Learner ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° - ‡∏à‡∏∞‡πÉ‡∏ä‡πâ Dynamic Weight ‡πÅ‡∏ó‡∏ô")
    missing_files = []
    if meta_learner.xgb_clf is None:
        missing_files.append("XGBoost Classifier")
    if meta_learner.xgb_reg is None:
        missing_files.append("XGBoost Regressor") 
    if meta_learner.scaler_dir is None:
        missing_files.append("Direction Scaler")
    if meta_learner.scaler_price is None:
        missing_files.append("Price Scaler")
    print(f"   ‡∏Ç‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå: {missing_files}")
    print("   üí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ XGBoost Meta-Learner:")
    print("      1. ‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏ó‡∏£‡∏ô XGBoost ‡∏Å‡πà‡∏≠‡∏ô")
    print("      2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå .pkl ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô directory ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô")

def fetch_latest_data():
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        engine = sqlalchemy.create_engine(DB_CONNECTION)

        query = f"""
            SELECT 
                StockDetail.Date, 
                StockDetail.StockSymbol, 
                Stock.Market,  
                StockDetail.OpenPrice AS Open, 
                StockDetail.HighPrice AS High, 
                StockDetail.LowPrice AS Low, 
                StockDetail.ClosePrice AS Close, 
                StockDetail.Volume, 
                StockDetail.P_BV_Ratio,
                StockDetail.Sentiment, 
                StockDetail.Changepercen AS Change_Percent, 
                StockDetail.TotalRevenue, 
                StockDetail.QoQGrowth, 
                StockDetail.EPS, 
                StockDetail.ROE, 
                StockDetail.NetProfitMargin, 
                StockDetail.DebtToEquity, 
                StockDetail.PERatio, 
                StockDetail.Dividend_Yield, 
                StockDetail.positive_news, 
                StockDetail.negative_news, 
                StockDetail.neutral_news,
                StockDetail.PredictionClose_GRU, 
                StockDetail.PredictionClose_LSTM, 
                StockDetail.PredictionTrend_GRU, 
                StockDetail.PredictionTrend_LSTM 
            FROM StockDetail
            LEFT JOIN Stock ON StockDetail.StockSymbol = Stock.StockSymbol
            WHERE Stock.Market = '{market_filter}'  
            AND StockDetail.Date >= CURDATE() - INTERVAL 350 DAY
            ORDER BY StockDetail.StockSymbol, StockDetail.Date ASC;
        """

        df = pd.read_sql(query, engine)
        engine.dispose()

        if df.empty:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà")
            return df

        # Data processing
        df['Date'] = pd.to_datetime(df['Date'])
        
        # Fill missing dates for each stock
        grouped = df.groupby('StockSymbol')
        filled_dfs = []
        
        for name, group in grouped:
            # Create complete date range for this stock
            all_dates = pd.date_range(start=group['Date'].min(), end=group['Date'].max(), freq='D')
            temp_df = pd.DataFrame({'Date': all_dates})
            temp_df['StockSymbol'] = name
            # Merge with original data
            merged = pd.merge(temp_df, group, on=['StockSymbol', 'Date'], how='left')
            # Forward fill missing values
            financial_cols = [
                'TotalRevenue', 'QoQGrowth', 'EPS', 'ROE',
                'NetProfitMargin', 'DebtToEquity', 'PERatio', 'Dividend_Yield'
            ]
            merged[financial_cols] = merged[financial_cols].fillna(0)
            merged = merged.ffill()
            filled_dfs.append(merged)
        
        df = pd.concat(filled_dfs, ignore_index=True)
        
        # Calculate technical indicators for each stock - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç DeprecationWarning
        def calculate_indicators(group):
            if len(group) < 14:
                return group
                
            try:
                # Calculate RSI
                group['RSI'] = ta.momentum.RSIIndicator(group['Close'], window=14).rsi()
                
                # Calculate EMAs
                group['EMA_12'] = group['Close'].ewm(span=12, adjust=False).mean()
                group['EMA_26'] = group['Close'].ewm(span=26, adjust=False).mean()
                group['EMA_10'] = group['Close'].ewm(span=10, adjust=False).mean()
                group['EMA_20'] = group['Close'].ewm(span=20, adjust=False).mean()
                
                # Calculate SMAs
                group['SMA_50'] = group['Close'].rolling(window=50).mean()
                group['SMA_200'] = group['Close'].rolling(window=200).mean()
                
                # Calculate MACD
                group['MACD'] = group['EMA_12'] - group['EMA_26']
                group['MACD_Signal'] = group['MACD'].rolling(window=9).mean()
                
                # Calculate ATR
                if len(group) >= 14:
                    atr = ta.volatility.AverageTrueRange(high=group['High'], low=group['Low'], close=group['Close'], window=14)
                    group['ATR'] = atr.average_true_range()
                
                # Calculate Bollinger Bands
                bollinger = ta.volatility.BollingerBands(group['Close'], window=20, window_dev=2)
                group['Bollinger_High'] = bollinger.bollinger_hband()
                group['Bollinger_Low'] = bollinger.bollinger_lband()
                
                # Convert Sentiment to numerical values
                group['Sentiment'] = group['Sentiment'].map({'Positive': 1, 'Negative': -1, 'Neutral': 0})
                
                # Calculate Keltner Channel
                keltner = ta.volatility.KeltnerChannel(high=group['High'], low=group['Low'], close=group['Close'], window=20, window_atr=10)
                group['Keltner_High'] = keltner.keltner_channel_hband()
                group['Keltner_Low'] = keltner.keltner_channel_lband()
                group['Keltner_Middle'] = keltner.keltner_channel_mband()
                
                # Calculate Chaikin Volatility
                window_cv = 10
                group['High_Low_Diff'] = group['High'] - group['Low']
                group['High_Low_EMA'] = group['High_Low_Diff'].ewm(span=window_cv, adjust=False).mean()
                group['Chaikin_Vol'] = group['High_Low_EMA'].pct_change(periods=window_cv) * 100
                
                # Calculate Donchian Channel
                window_dc = 20
                group['Donchian_High'] = group['High'].rolling(window=window_dc).max()
                group['Donchian_Low'] = group['Low'].rolling(window=window_dc).min()
                
                # Calculate PSAR
                psar = ta.trend.PSARIndicator(high=group['High'], low=group['Low'], close=group['Close'], step=0.02, max_step=0.2)
                group['PSAR'] = psar.psar()
                
                # Add date-related features
                group['DayOfWeek'] = group['Date'].dt.dayofweek
                group['Is_Day_0'] = (group['Date'].dt.dayofweek == 0).astype(int)  # Monday
                group['Is_Day_4'] = (group['Date'].dt.dayofweek == 4).astype(int)  # Friday
                group['DayOfMonth'] = group['Date'].dt.day
                group['IsFirstHalfOfMonth'] = (group['Date'].dt.day <= 15).astype(int)
                group['IsSecondHalfOfMonth'] = (group['Date'].dt.day > 15).astype(int)
                
            except Exception as e:
                print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {group['StockSymbol'].iloc[0] if not group.empty else 'Unknown'}: {e}")
            
            return group
        
        # Apply indicators calculation to each stock group - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç DeprecationWarning
        df = df.groupby('StockSymbol', group_keys=False).apply(calculate_indicators)
        df = df.reset_index(drop=True)
        
        # Handle missing values
        critical_columns = ['Open', 'High', 'Low', 'Close']
        df = df.dropna(subset=critical_columns)
        
        # Fill NaN values
        df = df.ffill().bfill()
        
        # Fill remaining NaN with 0 for technical indicators
        technical_columns = ['RSI', 'MACD', 'MACD_Signal', 'ATR', 
                            'Bollinger_High', 'Bollinger_Low', 'SMA_50', 'SMA_200',
                            'EMA_10', 'EMA_20', 'Keltner_High', 'Keltner_Low', 'Keltner_Middle',
                            'Chaikin_Vol', 'Donchian_High', 'Donchian_Low', 'PSAR']
        
        for col in technical_columns:
            if col in df.columns:
                df[col] = df[col].fillna(0)
        
        # Fill remaining NaN with 0
        df = df.fillna(0)
        
        print(f"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: {len(df)} ‡πÅ‡∏ñ‡∏ß, {len(df['StockSymbol'].unique())} ‡∏´‡∏∏‡πâ‡∏ô")
        print(f"üìä Technical indicators ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ: {[col for col in technical_columns if col in df.columns]}")
        
        return df
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()

def calculate_dynamic_weights(df_ticker, price_weight_factor=0.6, direction_weight_factor=0.4):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì dynamic weight ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á LSTM ‡πÅ‡∏•‡∏∞ GRU ‡∏ï‡∏≤‡∏° performance ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    """
    
    # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 15 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weight
    recent_data = df_ticker.tail(15)
    
    if len(recent_data) < 5:
        # ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏ä‡πâ weight ‡πÄ‡∏ó‡πà‡∏≤‡πÜ ‡∏Å‡∏±‡∏ô
        return 0.5, 0.5
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ columns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì accuracy ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    required_cols = ['PredictionClose_LSTM', 'PredictionClose_GRU', 
                     'PredictionTrend_LSTM', 'PredictionTrend_GRU']
    
    if not all(col in df_ticker.columns for col in required_cols):
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• predictions ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dynamic weighting")
        return 0.5, 0.5
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì price performance
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á predictions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö error calculation
        lstm_predictions = recent_data['PredictionClose_LSTM'].dropna()
        gru_predictions = recent_data['PredictionClose_GRU'].dropna()
        actual_prices = recent_data['Close'].dropna()
        
        if len(lstm_predictions) >= 3 and len(gru_predictions) >= 3 and len(actual_prices) >= 3:
            # ‡πÉ‡∏ä‡πâ length ‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á index mismatch
            min_len = min(len(lstm_predictions), len(gru_predictions), len(actual_prices))
            
            if min_len >= 2:
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MAE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö price predictions - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç index alignment
                lstm_pred_vals = lstm_predictions.iloc[:min_len-1].values
                gru_pred_vals = gru_predictions.iloc[:min_len-1].values
                actual_vals_next = actual_prices.iloc[1:min_len].values
                
                lstm_price_error = np.mean(np.abs(lstm_pred_vals - actual_vals_next))
                gru_price_error = np.mean(np.abs(gru_pred_vals - actual_vals_next))
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì direction accuracy - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç index alignment
                actual_vals_current = actual_prices.iloc[:min_len-1].values
                
                lstm_dir_pred = (lstm_pred_vals > actual_vals_current).astype(int)
                gru_dir_pred = (gru_pred_vals > actual_vals_current).astype(int)
                actual_dir = (actual_vals_next > actual_vals_current).astype(int)
                
                lstm_dir_acc = np.mean(lstm_dir_pred == actual_dir)
                gru_dir_acc = np.mean(gru_dir_pred == actual_dir)
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weights
                total_price_error = lstm_price_error + gru_price_error
                if total_price_error > 0:
                    lstm_price_score = gru_price_error / total_price_error  # ‡∏Å‡∏•‡∏±‡∏ö‡∏Ñ‡πà‡∏≤
                    gru_price_score = lstm_price_error / total_price_error
                else:
                    lstm_price_score = 0.5
                    gru_price_score = 0.5
                
                total_dir_acc = lstm_dir_acc + gru_dir_acc
                if total_dir_acc > 0:
                    lstm_dir_score = lstm_dir_acc / total_dir_acc
                    gru_dir_score = gru_dir_acc / total_dir_acc
                else:
                    lstm_dir_score = 0.5
                    gru_dir_score = 0.5
                
                # ‡∏£‡∏ß‡∏° weights
                lstm_weight = (price_weight_factor * lstm_price_score + 
                              direction_weight_factor * lstm_dir_score)
                gru_weight = (price_weight_factor * gru_price_score + 
                             direction_weight_factor * gru_dir_score)
                
                # Normalize
                total_weight = lstm_weight + gru_weight
                if total_weight > 0:
                    lstm_weight = lstm_weight / total_weight
                    gru_weight = gru_weight / total_weight
                else:
                    lstm_weight = 0.5
                    gru_weight = 0.5
                
                # Apply constraints
                lstm_weight = max(MIN_WEIGHT, min(MAX_WEIGHT, lstm_weight))
                gru_weight = max(MIN_WEIGHT, min(MAX_WEIGHT, gru_weight))
                
                # Re-normalize
                total_weight = lstm_weight + gru_weight
                lstm_weight = lstm_weight / total_weight
                gru_weight = gru_weight / total_weight
                
                return lstm_weight, gru_weight
            
    except Exception as e:
        print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì dynamic weights: {e}")
    
    return 0.5, 0.5

def predict_future_day_with_meta(model_lstm, model_gru, df, feature_columns, 
                                scaler_features, scaler_target, ticker_encoder, seq_length):
    """
    ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ LSTM/GRU + XGBoost Meta-Learner
    """
    
    future_predictions = []
    tickers = df['StockSymbol'].unique()
    
    print("\nüîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ 3-Layer Ensemble (LSTM + GRU + XGBoost)...")

    for ticker in tickers:
        print(f"\nüìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏∏‡πâ‡∏ô: {ticker}")
        df_ticker = df[df['StockSymbol'] == ticker].sort_values('Date').reset_index(drop=True)

        if len(df_ticker) < seq_length:
            print(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker}, ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...")
            continue

        try:
            # 1. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ LSTM ‡πÅ‡∏•‡∏∞ GRU
            latest_data = df_ticker.iloc[-seq_length:]
            features_scaled = scaler_features.transform(latest_data[feature_columns])
            ticker_ids = latest_data["Ticker_ID"].values
            market_ids = latest_data["Market_ID"].values

            X_feat = features_scaled.reshape(1, seq_length, -1)
            X_ticker = ticker_ids.reshape(1, seq_length)
            X_market = market_ids.reshape(1, seq_length)

            # LSTM predictions
            pred_output_lstm = model_lstm.predict([X_feat, X_ticker, X_market], verbose=0)
            pred_price_lstm_scaled = np.squeeze(pred_output_lstm[0])
            pred_direction_lstm = np.squeeze(pred_output_lstm[1])
            pred_price_lstm = scaler_target.inverse_transform(pred_price_lstm_scaled.reshape(-1, 1)).flatten()[0]

            # GRU predictions
            pred_output_gru = model_gru.predict([X_feat, X_ticker, X_market], verbose=0)
            pred_price_gru_scaled = np.squeeze(pred_output_gru[0])
            pred_direction_gru = np.squeeze(pred_output_gru[1])
            pred_price_gru = scaler_target.inverse_transform(pred_price_gru_scaled.reshape(-1, 1)).flatten()[0]

            # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost Meta-Learner
            meta_input = pd.DataFrame({
                'StockSymbol': [ticker],
                'Date': [df_ticker['Date'].max()],
                'Close': [df_ticker.iloc[-1]['Close']],
                'High': [df_ticker.iloc[-1]['High']] if 'High' in df_ticker.columns else [df_ticker.iloc[-1]['Close'] * 1.01],
                'Low': [df_ticker.iloc[-1]['Low']] if 'Low' in df_ticker.columns else [df_ticker.iloc[-1]['Close'] * 0.99],
                'PredictionClose_LSTM': [pred_price_lstm],
                'PredictionClose_GRU': [pred_price_gru],
                'PredictionTrend_LSTM': [1 if pred_direction_lstm > 0.5 else 0],
                'PredictionTrend_GRU': [1 if pred_direction_gru > 0.5 else 0]
            })
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö technical indicators
            historical_data = df_ticker.tail(30).copy()  # ‡πÉ‡∏ä‡πâ 30 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
            historical_data = pd.concat([historical_data, meta_input], ignore_index=True)
            
            # 3. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ XGBoost Meta-Learner
            meta_predictions = meta_learner.predict_meta(historical_data)
            
            if 'XGB_Predicted_Price' in meta_predictions.columns:
                # ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å XGBoost
                final_predicted_price = meta_predictions['XGB_Predicted_Price'].iloc[-1]
                final_predicted_direction = meta_predictions['XGB_Predicted_Direction'].iloc[-1]
                final_direction_prob = meta_predictions['XGB_Predicted_Direction_Proba'].iloc[-1]
                xgb_confidence = meta_predictions['XGB_Confidence'].iloc[-1]
                ensemble_method = "XGBoost Meta-Learner"
            else:
                # Fallback: ‡πÉ‡∏ä‡πâ Dynamic Weight ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á LSTM ‡πÅ‡∏•‡∏∞ GRU
                lstm_weight, gru_weight = calculate_dynamic_weights(df_ticker)
                final_predicted_price = lstm_weight * pred_price_lstm + gru_weight * pred_price_gru
                final_direction_prob = lstm_weight * pred_direction_lstm + gru_weight * pred_direction_gru
                final_predicted_direction = 1 if final_direction_prob > 0.5 else 0
                xgb_confidence = abs(final_direction_prob - 0.5) * 2
                ensemble_method = "Dynamic Weight Fallback"

            # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            last_date = df_ticker['Date'].max()
            next_day = last_date + pd.Timedelta(days=1)
            current_close = df_ticker.iloc[-1]['Close']
            
            # Model agreement
            lstm_dir = 1 if pred_direction_lstm > 0.5 else 0
            gru_dir = 1 if pred_direction_gru > 0.5 else 0
            model_agreement = 1 if lstm_dir == gru_dir else 0
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            prediction_result = {
                'StockSymbol': ticker,
                'Date': next_day,
                'Predicted_Price': final_predicted_price,
                'Predicted_Direction': final_predicted_direction,
                'Direction_Probability': final_direction_prob,
                'XGB_Confidence': xgb_confidence,
                'Ensemble_Method': ensemble_method,
                'LSTM_Direction': lstm_dir,
                'GRU_Direction': gru_dir,
                'LSTM_Prediction': pred_price_lstm,
                'GRU_Prediction': pred_price_gru,
                'Last_Close': current_close,
                'Price_Change': final_predicted_price - current_close,
                'Price_Change_Percent': (final_predicted_price - current_close) / current_close * 100,
                'Model_Agreement': model_agreement
            }
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• debug ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost
            if 'XGB_Predicted_Price' in meta_predictions.columns:
                price_change_pct = prediction_result['Price_Change_Percent']
                direction_consistent = ((price_change_pct > 0 and final_predicted_direction == 1) or 
                                      (price_change_pct <= 0 and final_predicted_direction == 0))
                consistency_status = "‚úÖ" if direction_consistent else "‚ùå"
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤
                raw_price = meta_predictions['XGB_Predicted_Price_Raw'].iloc[-1] if 'XGB_Predicted_Price_Raw' in meta_predictions.columns else final_predicted_price
                raw_change = (raw_price - current_close) / current_close * 100
                
                print(f"    üéØ Direction: {int(final_predicted_direction)} (Confidence: {xgb_confidence:.3f})")
                print(f"    üìä Price: {raw_change:+.2f}% ‚Üí {price_change_pct:+.2f}% {consistency_status}")
            
            future_predictions.append(prediction_result)
            
            print(f"‚úÖ {ticker}: {ensemble_method} - "
                  f"Price: {final_predicted_price:.2f} "
                  f"({prediction_result['Price_Change_Percent']:.2f}%) "
                  f"Confidence: {xgb_confidence:.3f}")
                  
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ {ticker}: {e}")
            continue

    return pd.DataFrame(future_predictions)

def save_predictions_simple(predictions_df):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
    ‡πÄ‡∏Å‡πá‡∏ö: ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà, ‡∏´‡∏∏‡πâ‡∏ô, ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (LSTM, GRU, Ensemble), ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (LSTM, GRU, Ensemble)
    """
    if predictions_df.empty:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
        return False

    try:
        engine = sqlalchemy.create_engine(DB_CONNECTION)
        
        with engine.connect() as connection:
            success_count = 0
            created_count = 0
            updated_count = 0
            
            for _, row in predictions_df.iterrows():
                try:
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ record ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    check_query = sqlalchemy.text("""
                        SELECT COUNT(*) FROM StockDetail 
                        WHERE StockSymbol = :symbol AND Date = :date
                    """)
                    
                    result = connection.execute(check_query, {
                        'symbol': row['StockSymbol'],
                        'date': row['Date'].strftime('%Y-%m-%d')
                    })
                    exists = result.scalar()
                    
                    if exists > 0:
                        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï predictions ‡∏ó‡∏±‡πâ‡∏á LSTM, GRU, ‡πÅ‡∏•‡∏∞ Ensemble
                        update_query = sqlalchemy.text("""
                            UPDATE StockDetail
                            SET PredictionClose_LSTM = :lstm_price,
                                PredictionTrend_LSTM = :lstm_trend,
                                PredictionClose_GRU = :gru_price,
                                PredictionTrend_GRU = :gru_trend,
                                PredictionClose_Ensemble = :ensemble_price, 
                                PredictionTrend_Ensemble = :ensemble_trend
                            WHERE StockSymbol = :symbol AND Date = :date
                        """)
                        
                        connection.execute(update_query, {
                            'lstm_price': float(row.get('LSTM_Prediction', row['Predicted_Price'])),
                            'lstm_trend': int(row.get('LSTM_Direction', row['Predicted_Direction'])),
                            'gru_price': float(row.get('GRU_Prediction', row['Predicted_Price'])),
                            'gru_trend': int(row.get('GRU_Direction', row['Predicted_Direction'])),
                            'ensemble_price': float(row['Predicted_Price']),
                            'ensemble_trend': int(row['Predicted_Direction']),
                            'symbol': row['StockSymbol'],
                            'date': row['Date'].strftime('%Y-%m-%d')
                        })
                        print(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï {row['StockSymbol']} (LSTM+GRU+Ensemble)")
                        updated_count += 1
                        
                    else:
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á record ‡πÉ‡∏´‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° predictions ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                        insert_query = sqlalchemy.text("""
                            INSERT INTO StockDetail 
                            (StockSymbol, Date, 
                             PredictionClose_LSTM, PredictionTrend_LSTM,
                             PredictionClose_GRU, PredictionTrend_GRU,
                             PredictionClose_Ensemble, PredictionTrend_Ensemble)
                            VALUES 
                            (:symbol, :date, 
                             :lstm_price, :lstm_trend,
                             :gru_price, :gru_trend,
                             :ensemble_price, :ensemble_trend)
                        """)
                        
                        connection.execute(insert_query, {
                            'symbol': row['StockSymbol'],
                            'date': row['Date'].strftime('%Y-%m-%d'),
                            'lstm_price': float(row.get('LSTM_Prediction', row['Predicted_Price'])),
                            'lstm_trend': int(row.get('LSTM_Direction', row['Predicted_Direction'])),
                            'gru_price': float(row.get('GRU_Prediction', row['Predicted_Price'])),
                            'gru_trend': int(row.get('GRU_Direction', row['Predicted_Direction'])),
                            'ensemble_price': float(row['Predicted_Price']),
                            'ensemble_trend': int(row['Predicted_Direction'])
                        })
                        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà {row['StockSymbol']} (LSTM+GRU+Ensemble)")
                        created_count += 1
                    
                    success_count += 1
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {row['StockSymbol']}: {e}")
                    continue
            
            # Commit ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
            connection.commit()
            
            print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
            print(f"   üìä ‡∏£‡∏ß‡∏°: {success_count}/{len(predictions_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            if updated_count > 0:
                print(f"   üîÑ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï: {updated_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            if created_count > 0:
                print(f"   ‚ûï ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà: {created_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            print(f"   üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: LSTM + GRU + Ensemble predictions")
            
            return success_count > 0
            
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        import traceback
        traceback.print_exc()
        return False

# ======================== MAIN EXECUTION ========================

if __name__ == "__main__":
    print("\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏ö‡∏ö Enhanced 3-Layer Ensemble")
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÅ‡∏•‡∏∞ GRU
    print("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÅ‡∏•‡∏∞ GRU...")
    
    if not os.path.exists(MODEL_LSTM_PATH):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡∏ó‡∏µ‡πà {MODEL_LSTM_PATH}")
        exit()
    
    if not os.path.exists(MODEL_GRU_PATH):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• GRU ‡∏ó‡∏µ‡πà {MODEL_GRU_PATH}")
        exit()
    
    try:
        model_lstm = load_model(MODEL_LSTM_PATH, compile=False)
        model_gru = load_model(MODEL_GRU_PATH, compile=False)
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÅ‡∏•‡∏∞ GRU ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•
        print(f"üìä LSTM model: {len(model_lstm.layers)} layers")
        print(f"üìä GRU model: {len(model_gru.layers)} layers")
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
        exit()
    
    # ‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    print("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    test_df = fetch_latest_data()
    
    if test_df.empty:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
        exit()
    
    print(f"üìä ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(test_df)} ‡πÅ‡∏ñ‡∏ß ‡∏à‡∏≤‡∏Å {len(test_df['StockSymbol'].unique())} ‡∏´‡∏∏‡πâ‡∏ô")
    print(f"üìã Columns ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {list(test_df.columns)}")
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° feature columns - ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ columns ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
    base_feature_columns = [
        'Open', 'High', 'Low', 'Close', 'Volume', 'Change_Percent', 'Sentiment',
        'positive_news', 'negative_news', 'neutral_news',
        'TotalRevenue', 'QoQGrowth', 'EPS', 'ROE', 'NetProfitMargin', 
        'DebtToEquity', 'PERatio', 'Dividend_Yield', 'P_BV_Ratio'
    ]
    
    # Technical indicators ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ
    potential_technical_columns = [
        'ATR', 'Keltner_High', 'Keltner_Low', 'Keltner_Middle', 'Chaikin_Vol',
        'Donchian_High', 'Donchian_Low', 'PSAR',
        'RSI', 'EMA_10', 'EMA_20', 'MACD', 'MACD_Signal', 
        'Bollinger_High', 'Bollinger_Low', 'SMA_50', 'SMA_200'
    ]
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ columns ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
    available_columns = [col for col in base_feature_columns if col in test_df.columns]
    available_technical = [col for col in potential_technical_columns if col in test_df.columns]
    
    feature_columns = available_columns + available_technical
    
    print(f"üìã Available feature columns ({len(feature_columns)}): {feature_columns}")
    missing_cols = set(base_feature_columns + potential_technical_columns) - set(feature_columns)
    if missing_cols:
        print(f"‚ö†Ô∏è Missing columns: {missing_cols}")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    if len(feature_columns) < 10:
        print("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• features ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10 columns")
        exit()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• predictions ‡∏à‡∏≤‡∏Å LSTM/GRU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    prediction_cols = ['PredictionClose_LSTM', 'PredictionClose_GRU', 
                      'PredictionTrend_LSTM', 'PredictionTrend_GRU']
    available_predictions = [col for col in prediction_cols if col in test_df.columns]
    print(f"üîÆ Available prediction columns: {available_predictions}")
    
    if len(available_predictions) < 4:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• predictions ‡∏à‡∏≤‡∏Å LSTM/GRU ‡∏Ñ‡∏£‡∏ö, XGBoost Meta-Learner ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ encoders ‡πÅ‡∏•‡∏∞ scalers
    us_stock = ['AAPL', 'NVDA', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'AVGO', 'TSM', 'AMD']
    thai_stock = ['ADVANC', 'INTUCH', 'TRUE', 'DITTO', 'DIF', 
                  'INSET', 'JMART', 'INET', 'JAS', 'HUMAN']
    test_df['Market_ID'] = test_df['StockSymbol'].apply(
        lambda x: "US" if x in us_stock else "TH" if x in thai_stock else "OTHER"
    )
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ï‡∏•‡∏≤‡∏î
    market_dist = test_df['Market_ID'].value_counts()
    print(f"üìà ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡∏ï‡∏•‡∏≤‡∏î: {dict(market_dist)}")
    
    scaler_main_features = RobustScaler()
    scaler_main_target = RobustScaler()
    ticker_encoder = LabelEncoder()
    market_encoder = LabelEncoder()
    
    try:
        test_df["Ticker_ID"] = ticker_encoder.fit_transform(test_df["StockSymbol"])
        test_df['Market_ID'] = market_encoder.fit_transform(test_df['Market_ID'])
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô fit scaler
        feature_data = test_df[feature_columns]
        if feature_data.isnull().any().any():
            print("‚ö†Ô∏è ‡∏û‡∏ö NaN ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• features, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£...")
            feature_data = feature_data.fillna(feature_data.mean())
            test_df[feature_columns] = feature_data
        
        scaler_main_features.fit(test_df[feature_columns])
        scaler_main_target.fit(test_df[["Close"]])
        
        print("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ scalers ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°...")
        print(f"   Shape ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {test_df.shape}")
        print(f"   Data types: {test_df[feature_columns].dtypes}")
        print(f"   NaN counts: {test_df[feature_columns].isnull().sum()}")
        exit()
    
    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Enhanced 3-Layer Ensemble
    future_predictions_df = predict_future_day_with_meta(
        model_lstm, model_gru, test_df, feature_columns, 
        scaler_main_features, scaler_main_target, ticker_encoder, SEQ_LENGTH
    )
    
    if not future_predictions_df.empty:
        print("\nüéØ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ Enhanced 3-Layer Ensemble:")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        output_path = 'enhanced_3layer_predictions.csv'
        future_predictions_df.to_csv(output_path, index=False)
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô {output_path}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        display_cols = ['StockSymbol', 'Date', 'Last_Close', 'Predicted_Price', 
                       'Price_Change_Percent', 'Predicted_Direction', 'XGB_Confidence',
                       'Ensemble_Method', 'Model_Agreement']
        
        print(future_predictions_df[display_cols])
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Direction Consistency
        print(f"\nüîç ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Direction Consistency:")
        consistent_count = 0
        total_count = len(future_predictions_df)
        
        for _, row in future_predictions_df.iterrows():
            price_change = row['Price_Change_Percent']
            predicted_dir = row['Predicted_Direction']
            is_consistent = ((price_change > 0 and predicted_dir == 1) or 
                           (price_change <= 0 and predicted_dir == 0))
            
            status = "‚úÖ" if is_consistent else "‚ùå"
            
            print(f"   {row['StockSymbol']}: {price_change:+6.2f}% ‚Üí Dir: {int(predicted_dir)} {status}")
            
            if is_consistent:
                consistent_count += 1
        
        consistency_rate = (consistent_count / total_count) * 100
        print(f"\nüìä Direction-Price Consistency: {consistent_count}/{total_count} ({consistency_rate:.1f}%)")
        
        print(f"\nüí° ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: Direction-First Approach")
        print(f"   üéØ ‡πÉ‡∏ä‡πâ Direction Classifier ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô)")
        print(f"   üìä ‡∏õ‡∏£‡∏±‡∏ö Price ‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Direction ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ")
        print(f"   ‚úÖ ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô Consistency = 100%")
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        method_counts = future_predictions_df['Ensemble_Method'].value_counts()
        print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Ensemble Methods:")
        for method, count in method_counts.items():
            percentage = (count / len(future_predictions_df)) * 100
            print(f"   {method}: {count} ‡∏´‡∏∏‡πâ‡∏ô ({percentage:.1f}%)")
        
        # ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ confidence ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        high_confidence = future_predictions_df.nlargest(3, 'XGB_Confidence')
        print(f"\nüèÜ ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ Direction Confidence ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î:")
        for _, row in high_confidence.iterrows():
            direction_text = "üìà BUY" if row['Predicted_Direction'] == 1 else "üìâ SELL/SHORT"
            print(f"   {row['StockSymbol']}: {direction_text} (Confidence: {row['XGB_Confidence']:.3f}, "
                  f"Expected: {row['Price_Change_Percent']:.2f}%)")
        
        # ‡πÅ‡∏¢‡∏Å‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á
        buy_signals = future_predictions_df[future_predictions_df['Predicted_Direction'] == 1]
        sell_signals = future_predictions_df[future_predictions_df['Predicted_Direction'] == 0]
        
        print(f"\nüìà BUY Signals ({len(buy_signals)} ‡∏´‡∏∏‡πâ‡∏ô):")
        if not buy_signals.empty:
            buy_sorted = buy_signals.sort_values('XGB_Confidence', ascending=False)
            for _, row in buy_sorted.iterrows():
                print(f"   {row['StockSymbol']}: +{row['Price_Change_Percent']:.2f}% (Confidence: {row['XGB_Confidence']:.3f})")
        
        print(f"\nüìâ SELL/SHORT Signals ({len(sell_signals)} ‡∏´‡∏∏‡πâ‡∏ô):")
        if not sell_signals.empty:
            sell_sorted = sell_signals.sort_values('XGB_Confidence', ascending=False)
            for _, row in sell_sorted.iterrows():
                print(f"   {row['StockSymbol']}: {row['Price_Change_Percent']:.2f}% (Confidence: {row['XGB_Confidence']:.3f})")
        
        print(f"\nüéØ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
        print(f"   ‚Ä¢ Confidence > 0.5: ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ")
        print(f"   ‚Ä¢ Confidence > 0.4: ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏î‡∏µ")
        print(f"   ‚Ä¢ Confidence < 0.3: ‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print(f"\nüíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        db_save_success = save_predictions_simple(future_predictions_df)
        
        if db_save_success:
            print("üîÑ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÅ‡∏•‡πâ‡∏ß")
            print("üì± ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß")
        else:
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå CSV ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    
    else:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á")