import yfinance as yf
import pandas as pd
import datetime
import sys
import os
from dotenv import load_dotenv
import io
from pandas_market_calendars import get_calendar
import requests
import time
try:
    import mysql.connector
except ImportError:
    print("‚ö†Ô∏è mysql-connector-python not installed. Skipping database operations.")
    mysql = None

# ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô UnicodeEncodeError
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='ignore')

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
CURRENT_DIR = os.getcwd()
path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'config.env')
load_dotenv(path)

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")
FMP_API_KEY = os.getenv("FMP_API_KEY")  # ‡πÄ‡∏û‡∏¥‡πà‡∏° FMP API Key
ALPHA_VANTAGE_API_KEY = os.getenv("ALPHA_VANTAGE_API_KEY")  # ‡πÄ‡∏û‡∏¥‡πà‡∏° Alpha Vantage API Key

if not all([DB_HOST, DB_USER, DB_PASSWORD, DB_NAME]) and mysql:
    raise ValueError("‚ùå ‡∏Ç‡∏≤‡∏î‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env")

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
def check_table_structure():
    if not mysql:
        return False
    try:
        conn = mysql.connector.connect(
            host=DB_HOST,
            user=DB_USER,
            password=DB_PASSWORD,
            database=DB_NAME
        )
        cursor = conn.cursor()
        cursor.execute("SHOW COLUMNS FROM StockDetail")
        columns = [col[0] for col in cursor.fetchall()]
        cursor.close()
        conn.close()
        expected_columns = ['Date', 'StockSymbol']
        missing_columns = [col for col in expected_columns if col not in columns]
        if missing_columns:
            print(f"‚ùå Missing columns in StockDetail: {missing_columns}")
            print("‚ö†Ô∏è Using default start date (2018-01-01) due to table issues.")
            return False
        print("‚úÖ Table structure is sufficient for date checking")
        return True
    except Exception as e:
        print(f"‚ùå Error checking table structure: {e}")
        print("‚ö†Ô∏è Using default start date (2018-01-01) due to table issues.")
        return False

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Alpha Vantage
def get_alpha_vantage_data(ticker, api_key):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏à‡∏≤‡∏Å Alpha Vantage API
    """
    if not api_key:
        print("‚ö†Ô∏è Alpha Vantage API Key not found in environment variables")
        return None
    
    try:
        # ‡πÅ‡∏õ‡∏•‡∏á ticker format ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Alpha Vantage
        av_symbol = ticker  # ‡πÉ‡∏ä‡πâ .BK format
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Alpha Vantage API
        url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={av_symbol}&apikey={api_key}&outputsize=compact"
        
        print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} ‡∏à‡∏≤‡∏Å Alpha Vantage API...")
        
        # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠ API
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if 'Time Series (Daily)' not in data:
            if 'Error Message' in data:
                print(f"‚ö†Ô∏è Alpha Vantage Error for {ticker}: {data['Error Message']}")
            elif 'Information' in data:
                print(f"‚ö†Ô∏è Alpha Vantage Info for {ticker}: {data['Information']}")
            else:
                print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ‡∏à‡∏≤‡∏Å Alpha Vantage")
            return None
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame
        time_series = data['Time Series (Daily)']
        df_data = []
        
        for date_str, values in time_series.items():
            df_data.append({
                'Date': pd.to_datetime(date_str),
                'Open': float(values['1. open']),
                'High': float(values['2. high']),
                'Low': float(values['3. low']),
                'Close': float(values['4. close']),
                'Volume': int(values['5. volume'])
            })
        
        df = pd.DataFrame(df_data)
        df = df.set_index('Date').sort_index()
        
        # ‡∏•‡∏ö timezone ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        if df.index.tz is not None:
            df.index = df.index.tz_localize(None)
        
        print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} ‡∏à‡∏≤‡∏Å Alpha Vantage ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df)} ‡πÅ‡∏ñ‡∏ß")
        return df
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Network error for {ticker} from Alpha Vantage: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Error fetching {ticker} from Alpha Vantage: {e}")
        return None

def get_fmp_data(ticker, start_date, end_date, api_key):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏à‡∏≤‡∏Å Financial Modeling Prep API
    """
    if not api_key:
        print("‚ö†Ô∏è FMP API Key not found in environment variables")
        return None
    
    try:
        # ‡πÅ‡∏õ‡∏•‡∏á ticker format ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FMP (‡∏•‡∏ö .BK)
        fmp_symbol = ticker.replace('.BK', '')
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FMP API
        url = f"https://financialmodelingprep.com/api/v3/historical-price-full/{fmp_symbol}?apikey={api_key}"
        
        print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} ‡∏à‡∏≤‡∏Å FMP API...")
        
        # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠ API
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if 'historical' not in data or not data['historical']:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ‡∏à‡∏≤‡∏Å FMP")
            return None
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô DataFrame
        df = pd.DataFrame(data['historical'])
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
        df['date'] = pd.to_datetime(df['date'])
        df = df.set_index('date').sort_index()
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        start_dt = pd.to_datetime(start_date)
        end_dt = pd.to_datetime(end_date)
        df = df[(df.index >= start_dt) & (df.index <= end_dt)]
        
        # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö yfinance
        df = df.rename(columns={
            'open': 'Open',
            'high': 'High',
            'low': 'Low',
            'close': 'Close',
            'volume': 'Volume'
        })
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        df = df[required_columns]
        
        # ‡∏•‡∏ö timezone ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        if df.index.tz is not None:
            df.index = df.index.tz_localize(None)
        
        print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} ‡∏à‡∏≤‡∏Å FMP ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df)} ‡πÅ‡∏ñ‡∏ß")
        return df
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Network error for {ticker} from FMP: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Error fetching {ticker} from FMP: {e}")
        return None

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ fallback mechanism
def get_stock_data_with_fallback(ticker, start_date, end_date, max_retries=3):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏≠‡∏á yfinance -> FMP -> Alpha Vantage
    """
    data = None
    source_used = None
    
    # ‡∏•‡∏≠‡∏á yfinance ‡∏Å‡πà‡∏≠‡∏ô
    for attempt in range(max_retries):
        try:
            print(f"üì° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} ‡∏à‡∏≤‡∏Å yfinance (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1})...")
            stock = yf.Ticker(ticker)
            ticker_data = stock.history(start=start_date, end=end_date, interval='1d')
            
            if not ticker_data.empty:
                print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} ‡∏à‡∏≤‡∏Å yfinance ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(ticker_data)} ‡πÅ‡∏ñ‡∏ß")
                data = ticker_data
                source_used = "yfinance"
                break
            else:
                print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ‡∏à‡∏≤‡∏Å yfinance (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1})")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Error for {ticker} from yfinance (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1}): {e}")
        
        if attempt < max_retries - 1:
            time.sleep(2)  # ‡∏£‡∏≠ 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
    
    # ‡∏ñ‡πâ‡∏≤ yfinance ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏•‡∏≠‡∏á FMP
    if data is None or data.empty:
        print(f"üîÑ yfinance ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á FMP ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker}...")
        
        for attempt in range(max_retries):
            try:
                fmp_data = get_fmp_data(ticker, start_date, end_date, FMP_API_KEY)
                
                if fmp_data is not None and not fmp_data.empty:
                    data = fmp_data
                    source_used = "FMP"
                    break
                else:
                    print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ‡∏à‡∏≤‡∏Å FMP (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1})")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Error for {ticker} from FMP (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1}): {e}")
            
            if attempt < max_retries - 1:
                time.sleep(3)  # ‡∏£‡∏≠ 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà (FMP ‡∏°‡∏µ rate limit)
    
    # ‡∏ñ‡πâ‡∏≤ FMP ‡∏Å‡πá‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏•‡∏≠‡∏á Alpha Vantage
    if data is None or data.empty:
        print(f"üîÑ FMP ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á Alpha Vantage ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker}...")
        
        for attempt in range(max_retries):
            try:
                av_data = get_alpha_vantage_data(ticker, ALPHA_VANTAGE_API_KEY)
                
                if av_data is not None and not av_data.empty:
                    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                    start_dt = pd.to_datetime(start_date)
                    end_dt = pd.to_datetime(end_date)
                    av_data = av_data[(av_data.index >= start_dt) & (av_data.index <= end_dt)]
                    
                    if not av_data.empty:
                        data = av_data
                        source_used = "Alpha Vantage"
                        break
                    else:
                        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ‡∏à‡∏≤‡∏Å Alpha Vantage (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1})")
                else:
                    print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ‡∏à‡∏≤‡∏Å Alpha Vantage (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1})")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Error for {ticker} from Alpha Vantage (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1}): {e}")
            
            if attempt < max_retries - 1:
                time.sleep(15)  # ‡∏£‡∏≠ 15 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (Alpha Vantage ‡∏°‡∏µ rate limit ‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î)
    
    return data, source_used

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Volume anomalies
def check_volume_anomalies(data):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Volume ‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥"""
    print("\nüîç Volume Analysis:")
    
    for ticker in data['Ticker'].unique():
        ticker_data = data[data['Ticker'] == ticker].copy()
        ticker_data['Date'] = pd.to_datetime(ticker_data['Date'])
        
        # ‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà Volume = 0
        zero_volume_trading_days = ticker_data[
            (ticker_data['Volume'] == 0) & 
            (ticker_data['Date'].dt.dayofweek < 5)  # ‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå
        ]
        
        if len(zero_volume_trading_days) > 0:
            print(f"‚ö†Ô∏è {ticker}: Found {len(zero_volume_trading_days)} trading days with Volume = 0")
            print(f"   Dates: {zero_volume_trading_days['Date'].dt.strftime('%Y-%m-%d').tolist()}")
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ Volume
        non_zero_volume = ticker_data[ticker_data['Volume'] > 0]['Volume']
        if len(non_zero_volume) > 0:
            print(f"‚úÖ {ticker}: Avg Volume = {non_zero_volume.mean():,.0f}, "
                  f"Min = {non_zero_volume.min():,.0f}, "
                  f"Max = {non_zero_volume.max():,.0f}")
        else:
            print(f"‚ùå {ticker}: No valid volume data found!")

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
latest_dates = {}
tickers = ['ADVANC.BK', 'TRUE.BK', 'DITTO.BK', 'DIF.BK', 
           'INSET.BK', 'JMART.BK', 'INET.BK', 'JAS.BK', 'HUMAN.BK']
has_valid_table = False
today = datetime.datetime.now()
current_date = (today - datetime.timedelta(days=1)).strftime('%Y-%m-%d')

if all([DB_HOST, DB_USER, DB_PASSWORD, DB_NAME]) and mysql:
    try:
        conn = mysql.connector.connect(
            host=DB_HOST,
            user=DB_USER,
            password=DB_PASSWORD,
            database=DB_NAME,
            autocommit=True
        )
        cursor = conn.cursor()
        print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        has_valid_table = check_table_structure()
        
        if has_valid_table:
            for ticker in tickers:
                stock_name = ticker.replace('.BK', '')
                try:
                    cursor.execute("SELECT MAX(Date) FROM StockDetail WHERE StockSymbol = %s AND ClosePrice IS NOT NULL" , (stock_name,))
                    result = cursor.fetchone()[0]
                    if result is None:
                        latest_dates[ticker] = "2018-01-01"
                    elif result > today.date():
                        print(f"‚ö†Ô∏è Future date found for {ticker}: {result}. Using default start date (2018-01-01)")
                        latest_dates[ticker] = "2018-01-01"
                    else:
                        latest_dates[ticker] = (result + datetime.timedelta(days=1)).strftime('%Y-%m-%d')
                except Exception as e:
                    print(f"‚ö†Ô∏è Error fetching latest date for {ticker}: {e}")
                    latest_dates[ticker] = "2018-01-01"
        else:
            for ticker in tickers:
                latest_dates[ticker] = "2018-01-01"
        
        cursor.close()
        conn.close()
        print("üîπ ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß")
    except Exception as e:
        print(f"‚ùå Failed to connect to database: {e}")
        for ticker in tickers:
            latest_dates[ticker] = "2018-01-01"
else:
    print("‚ö†Ô∏è Missing database configuration or mysql-connector-python, using default start date (2018-01-01)")
    for ticker in tickers:
        latest_dates[ticker] = "2018-01-01"

# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î
start_date_db = min(latest_dates.values())
# ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô (‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 30 ‡∏ß‡∏±‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
start_date = (pd.to_datetime(min(latest_dates.values())) - datetime.timedelta(days=30)).strftime('%Y-%m-%d')
end_date = current_date

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if start_date >= end_date:
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á (start_date: {start_date} >= end_date: {end_date})")
    sys.exit(0)

print(f"üîπ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• API ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
print(f"üîß API Status:")
print(f"   - yfinance: ‚úÖ Available")
print(f"   - FMP API: {'‚úÖ Available' if FMP_API_KEY else '‚ùå No API Key'}")

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô SET ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢
try:
    set_calendar = get_calendar('XBKK')
    trading_days = set_calendar.schedule(start_date=start_date, end_date=end_date).index
    print("‚úÖ ‡πÉ‡∏ä‡πâ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô SET (XBKK) ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
except Exception as e:
    print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô SET ‡πÑ‡∏î‡πâ: {e}")
    # ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏ó‡∏ô (‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå)
    all_dates_range = pd.date_range(start=start_date, end=end_date, freq='D')
    trading_days = all_dates_range[all_dates_range.weekday < 5]  # 0=‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå, 4=‡∏®‡∏∏‡∏Å‡∏£‡πå
    print("‚úÖ ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå) ‡πÅ‡∏ó‡∏ô")

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
def is_trading_day(date, trading_days):
    return pd.Timestamp(date) in trading_days

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢ Forward Fill ‡πÅ‡∏•‡∏∞ Rolling Mean (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Volume)
def impute_holiday_data(ticker_data, all_dates, ticker, window=3):
    print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker}...")
    ticker_data = ticker_data.copy()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
    if not all(col in ticker_data.columns for col in required_columns):
        print(f"‚ùå Missing required columns for {ticker}: {required_columns}")
        return pd.DataFrame()
    
    # ‡πÅ‡∏õ‡∏•‡∏á index ‡πÄ‡∏õ‡πá‡∏ô datetime ‡πÅ‡∏•‡∏∞‡∏•‡∏ö timezone
    ticker_data.index = pd.to_datetime(ticker_data.index).tz_localize(None)
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Volume ‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô reindex
    original_volume = ticker_data['Volume'].copy()
    original_volume = original_volume[original_volume > 0]  # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0
    
    print(f"üìä {ticker} - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö: {len(ticker_data)} ‡πÅ‡∏ñ‡∏ß")
    print(f"üìä {ticker} - ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ö: {ticker_data.index.min()} ‡∏ñ‡∏∂‡∏á {ticker_data.index.max()}")
    
    # Reindex ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
    ticker_data = ticker_data.reindex(all_dates, method=None)
    print(f"üìä {ticker} - ‡∏´‡∏•‡∏±‡∏á reindex: {len(ticker_data)} ‡πÅ‡∏ñ‡∏ß")
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
    missing_percentage = ticker_data[required_columns].isnull().mean() * 100
    print(f"üîç {ticker} - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: Open: {missing_percentage['Open']:.1f}%, High: {missing_percentage['High']:.1f}%, Low: {missing_percentage['Low']:.1f}%, Close: {missing_percentage['Close']:.1f}%, Volume: {missing_percentage['Volume']:.1f}%")
    
    if missing_percentage.sum() > 50:
        print(f"‚ö†Ô∏è Warning: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ({missing_percentage.sum():.2f}%)")
    
    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Forward Fill, Backward Fill ‡πÅ‡∏•‡∏∞ Rolling Mean
    print(f"üîÑ {ticker} - ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Forward Fill...")
    ticker_data[['Open', 'High', 'Low', 'Close']] = ticker_data[['Open', 'High', 'Low', 'Close']].ffill(limit=5)
    
    print(f"üîÑ {ticker} - ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Backward Fill...")
    ticker_data[['Open', 'High', 'Low', 'Close']] = ticker_data[['Open', 'High', 'Low', 'Close']].bfill(limit=5)
    
    print(f"üîÑ {ticker} - ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Rolling Mean (window={window})...")
    # ‡πÉ‡∏ä‡πâ rolling mean ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà
    for col in ['Open', 'High', 'Low', 'Close']:
        missing_mask = ticker_data[col].isnull()
        if missing_mask.any():
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì rolling mean ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
            rolling_mean = ticker_data[col].rolling(window=window, min_periods=1, center=True).mean()
            ticker_data.loc[missing_mask, col] = rolling_mean.loc[missing_mask]
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Volume ‡πÅ‡∏¢‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏≤‡∏Å - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Volume
    print(f"üîÑ {ticker} - ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Volume...")
    
    # ‡πÉ‡∏ä‡πâ SET trading calendar ‡∏´‡∏£‡∏∑‡∏≠ weekdays ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
    try:
        set_cal = get_calendar('XBKK')
        trading_schedule = set_cal.schedule(start_date=all_dates[0], end_date=all_dates[-1])
        trading_days_set = set(trading_schedule.index.normalize())
    except:
        # ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå‡πÅ‡∏ó‡∏ô
        trading_days_set = set(all_dates[all_dates.weekday < 5])
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Volume ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
    avg_volume = original_volume.mean() if len(original_volume) > 0 else 1000000
    
    for date in ticker_data.index:
        date_normalized = pd.Timestamp(date).normalize()
        
        if date_normalized in trading_days_set:
            # ‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Volume ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
            if pd.isna(ticker_data.loc[date, 'Volume']) or ticker_data.loc[date, 'Volume'] == 0:
                # ‡πÉ‡∏ä‡πâ forward fill ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
                prev_volumes = ticker_data.loc[:date, 'Volume'].dropna()
                prev_volumes = prev_volumes[prev_volumes > 0]
                
                if len(prev_volumes) > 0:
                    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á 3 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                    recent_avg = prev_volumes.tail(3).mean()
                    ticker_data.loc[date, 'Volume'] = recent_avg
                else:
                    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
                    ticker_data.loc[date, 'Volume'] = avg_volume
                    
                print(f"üîÑ Imputed volume for {ticker} on {date.strftime('%Y-%m-%d')}: {ticker_data.loc[date, 'Volume']:,.0f}")
        else:
            # ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î: ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô 0
            ticker_data.loc[date, 'Volume'] = 0
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Changepercent
    print(f"üîÑ {ticker} - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Changepercent...")
    ticker_data['Changepercent'] = ((ticker_data['Close'] - ticker_data['Open']) / ticker_data['Open'] * 100).fillna(0)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    final_missing = ticker_data[required_columns].isnull().mean() * 100
    print(f"‚úÖ {ticker} - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏¥‡∏°: Open: {final_missing['Open']:.1f}%, High: {final_missing['High']:.1f}%, Low: {final_missing['Low']:.1f}%, Close: {final_missing['Close']:.1f}%, Volume: {final_missing['Volume']:.1f}%")
    
    # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    original_dates = set(ticker_data.dropna(subset=['Open']).index)
    all_dates_set = set(ticker_data.index)
    imputed_dates = all_dates_set - original_dates
    print(f"üìà {ticker} - ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß {len(imputed_dates)} ‡∏ß‡∏±‡∏ô ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(all_dates_set)} ‡∏ß‡∏±‡∏ô")

    return ticker_data

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î)
all_dates = pd.date_range(start=start_date, end=end_date, freq='D')
print(f"üìÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {len(all_dates)} ‡∏ß‡∏±‡∏ô (‡∏à‡∏≤‡∏Å {start_date} ‡∏ñ‡∏∂‡∏á {end_date})")

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ fallback mechanism (yfinance -> FMP)
data_dict = {}
sources_used = {}

print("üîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ fallback mechanism...")
for ticker in tickers:
    ticker_data, source = get_stock_data_with_fallback(ticker, start_date, end_date, max_retries=3)
    
    if ticker_data is not None and not ticker_data.empty:
        print(f"üìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} (‡∏à‡∏≤‡∏Å {source}):")
        print(ticker_data.head(3).to_string())
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Volume ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        original_volumes = ticker_data['Volume'][ticker_data['Volume'] > 0]
        if len(original_volumes) > 0:
            print(f"üîµ Original volume stats for {ticker}: Mean={original_volumes.mean():,.0f}, Min={original_volumes.min():,.0f}, Max={original_volumes.max():,.0f}")
        
        # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
        ticker_data = impute_holiday_data(ticker_data, all_dates, ticker, window=3)  
        stock_name = ticker.replace('.BK', '')
        ticker_data['Ticker'] = stock_name
        data_dict[ticker] = ticker_data
        sources_used[ticker] = source
        print(f"‚úÖ ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker} ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô (‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {source})")
    else:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {ticker} ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á yfinance ‡πÅ‡∏•‡∏∞ FMP")

if not data_dict:
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á")
    sys.exit(0)

# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:")
for ticker, source in sources_used.items():
    print(f"üîπ {ticker}: {source}")

# ‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
data_list = []
total_imputed_days = 0

print("\nüîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î:")
for ticker, ticker_data in data_dict.items():
    if ticker_data.empty:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker}")
        continue
    
    # ‡∏ô‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    imputed_count = 0
    for date in ticker_data.index:
        if not is_trading_day(date, trading_days):
            if not ticker_data.loc[date, ['Open', 'High', 'Low', 'Close']].isnull().any():
                imputed_count += 1
                if imputed_count <= 3:  # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 3 ‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å
                    print(f"üìù {ticker} - {date.strftime('%Y-%m-%d')} (‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î): ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢")
    
    if imputed_count > 3:
        print(f"üìù {ticker} - ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {imputed_count} ‡∏ß‡∏±‡∏ô")
    
    total_imputed_days += imputed_count
    data_list.append(ticker_data)

print(f"\n‚úÖ ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_imputed_days} ‡∏ß‡∏±‡∏ô")

if not data_list:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏î ‡πÜ ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ")
    sys.exit(1)

# ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
print("üîÑ ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î...")
cleaned_data = pd.concat(data_list).reset_index()

# ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö CSV
cleaned_data = cleaned_data.rename(columns={
    'index': 'Date',
    'Ticker': 'Ticker',
    'Open': 'Open',
    'High': 'High',
    'Low': 'Low',
    'Close': 'Close',
    'Volume': 'Volume',
    'Changepercent': 'Changepercent'
})

cleaned_data['Date'] = pd.to_datetime(cleaned_data['Date']).dt.strftime('%Y-%m-%d')

# ‚úÖ ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
columns_to_keep = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume', 'Changepercent']
cleaned_data = cleaned_data[columns_to_keep]

# ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
print("üîπ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏≠‡∏Å...")
before_filter = len(cleaned_data)
cleaned_data = cleaned_data[
    (cleaned_data['Open'].notna()) &
    (cleaned_data['High'].notna()) &
    (cleaned_data['Low'].notna()) &
    (cleaned_data['Close'].notna()) &
    (cleaned_data['Date'] >= start_date_db) &
    (cleaned_data['Date'] <= end_date)
]
after_filter = len(cleaned_data)
print(f"üîπ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß: {before_filter} -> {after_filter} ‡πÅ‡∏ñ‡∏ß")

# ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
cleaned_data = cleaned_data.sort_values(['Date', 'Ticker']).reset_index(drop=True)
cleaned_data = cleaned_data.drop_duplicates(subset=['Date', 'Ticker'], keep='first')

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Volume ‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
check_volume_anomalies(cleaned_data)

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Volume = 0 ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢
print("\nüîß Checking for zero volume on trading days...")
cleaned_data['Date_dt'] = pd.to_datetime(cleaned_data['Date'])
cleaned_data['is_weekday'] = cleaned_data['Date_dt'].dt.dayofweek < 5

# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ Volume = 0 ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢
zero_volume_weekdays = cleaned_data[(cleaned_data['Volume'] == 0) & (cleaned_data['is_weekday'])]
if len(zero_volume_weekdays) > 0:
    print(f"‚ö†Ô∏è Found {len(zero_volume_weekdays)} records with zero volume on weekdays")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    for ticker in zero_volume_weekdays['Ticker'].unique():
        ticker_zeros = zero_volume_weekdays[zero_volume_weekdays['Ticker'] == ticker]
        print(f"   {ticker}: {len(ticker_zeros)} days - {ticker_zeros['Date'].tolist()}")

# ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠
cleaned_data = cleaned_data.drop(['Date_dt', 'is_weekday'], axis=1)

# ‚úÖ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
today = datetime.datetime.today().strftime('%Y-%m-%d')
initial_rows = len(cleaned_data)
cleaned_data = cleaned_data[cleaned_data['Date'].astype(str) != today]
if len(cleaned_data) < initial_rows:
    print(f"üîπ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ({today}) ‡πÅ‡∏•‡πâ‡∏ß")

# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV
csv_path = os.path.join(os.path.dirname(__file__), "Stock", "stock_data_thai.csv")
os.makedirs(os.path.dirname(csv_path), exist_ok=True)
cleaned_data.to_csv(csv_path, index=False)
print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {csv_path}")

# ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
print(f"üîπ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(cleaned_data)} ‡πÅ‡∏ñ‡∏ß")
print(f"üîπ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {cleaned_data['Date'].nunique()} ‡∏ß‡∏±‡∏ô")
if not cleaned_data.empty:
    print(f"üîπ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {cleaned_data['Date'].min()} ‡∏ñ‡∏∂‡∏á {cleaned_data['Date'].max()}")
    for ticker in cleaned_data['Ticker'].unique():
        ticker_data = cleaned_data[cleaned_data['Ticker'] == ticker]
        trading_days_count = len([d for d in ticker_data['Date'] if is_trading_day(pd.to_datetime(d), trading_days)])
        holiday_days_count = len(ticker_data) - trading_days_count
        source = sources_used.get(f"{ticker}.BK", "Unknown")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Average Volume
        avg_volume = ticker_data[ticker_data['Volume'] > 0]['Volume'].mean()
        avg_volume_str = f"{avg_volume:,.0f}" if not pd.isna(avg_volume) else "N/A"
        
        print(f"üîπ {ticker}: {len(ticker_data)} ‡πÅ‡∏ñ‡∏ß (‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢: {trading_days_count}, ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°: {holiday_days_count}), ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î {ticker_data['Date'].max()}, Avg Volume: {avg_volume_str} [‡πÅ‡∏´‡∏•‡πà‡∏á: {source}]")
    
    print("\nüìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î:")
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°
    sample_data = cleaned_data.head(15)
    for _, row in sample_data.iterrows():
        date_status = "‡∏ß‡∏±‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢" if is_trading_day(pd.to_datetime(row['Date']), trading_days) else "‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î(‡πÄ‡∏ï‡∏¥‡∏°)"
        print(f"  {row['Date']} | {row['Ticker']} | Close: {row['Close']:.2f} | Volume: {row['Volume']:,.0f} | ({date_status})")
else:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")