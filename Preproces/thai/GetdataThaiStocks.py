import yfinance as yf
import pandas as pd
import datetime
import sys
import os
import mysql.connector
from dotenv import load_dotenv
from pandas_market_calendars import get_calendar

# ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô UnicodeEncodeError
sys.stdout.reconfigure(encoding="utf-8", errors="ignore")

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
CURRENT_DIR = os.getcwd()
path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'config.env')
load_dotenv(path)

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

if not all([DB_HOST, DB_USER, DB_PASSWORD, DB_NAME]):
    raise ValueError("‚ùå ‡∏Ç‡∏≤‡∏î‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env")

# ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
conn = mysql.connector.connect(
    host=DB_HOST,
    user=DB_USER,
    password=DB_PASSWORD,
    database=DB_NAME,
    autocommit=True
)
cursor = conn.cursor()
print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢
tickers = ['ADVANC.BK', 'TRUE.BK', 'DITTO.BK', 'DIF.BK', 
           'INSET.BK', 'JMART.BK', 'INET.BK', 'JAS.BK', 'HUMAN.BK']

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
def is_holiday(date, trading_days):
    return pd.Timestamp(date) not in trading_days

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢ Rolling Mean
def impute_holiday_data(ticker_data, window=3):
    ticker_data = ticker_data.copy()
    ticker_data.index = pd.to_datetime(ticker_data.index)
    all_dates = pd.date_range(start=ticker_data.index.min(), end=ticker_data.index.max(), freq='D')
    ticker_data = ticker_data.reindex(all_dates)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢
    missing_percentage = ticker_data[['Open', 'High', 'Low', 'Close', 'Volume']].isnull().mean() * 100
    if missing_percentage.sum() > 20:
        print(f"‚ö†Ô∏è Warning: Excessive missing data ({missing_percentage.sum():.2f}%).")

    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Rolling Mean ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤
    ticker_data[['Open', 'High', 'Low', 'Close']] = (
        ticker_data[['Open', 'High', 'Low', 'Close']]
        .ffill(limit=2)  # Forward Fill ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏±‡πâ‡∏ô ‡πÜ
        .rolling(window=window, min_periods=1).mean()
    )

    # ‡∏ï‡∏±‡πâ‡∏á Volume ‡πÅ‡∏•‡∏∞ Changepercent ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
    ticker_data['Volume'] = ticker_data['Volume'].fillna(0)
    ticker_data['Changepercent'] = (ticker_data['Close'] - ticker_data['Open']) / ticker_data['Open'] * 100
    ticker_data['Changepercent'] = ticker_data['Changepercent'].fillna(0)

    return ticker_data

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
latest_dates = {}
end_date = datetime.datetime.today().strftime('%Y-%m-%d')  # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô

for ticker in tickers:
    stock_name = ticker.replace('.BK', '')
    cursor.execute("SELECT MAX(Date) FROM StockDetail WHERE StockSymbol = %s", (stock_name,))
    result = cursor.fetchone()[0]
    if result is None:
        latest_dates[ticker] = "2018-01-01"
    else:
        latest_dates[ticker] = (result + datetime.timedelta(days=1)).strftime('%Y-%m-%d')

# ‚úÖ ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
cursor.close()
conn.close()
print("üîπ ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß")

# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
start_date = min(latest_dates.values())

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if start_date > end_date:
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á (start_date: {start_date} > end_date: {end_date})")
    sys.exit(0)

print(f"üîπ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô SET ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
set_calendar = get_calendar('XBKK')
trading_days = set_calendar.schedule(start_date=start_date, end_date=end_date).index

# ‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ yfinance
max_retries = 3
retry_count = 0
data_dict = {}

while retry_count < max_retries:
    try:
        for ticker in tickers:
            stock = yf.Ticker(ticker)
            ticker_data = stock.history(start=start_date, end=end_date, interval='1d')
            if not ticker_data.empty:
                data_dict[ticker] = ticker_data
        if not data_dict:
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å yfinance")
            sys.exit(0)
        break
    except Exception as e:
        retry_count += 1
        print(f"‚ö†Ô∏è Error: {e} (‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà {retry_count}/{max_retries})")
        if retry_count == max_retries:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å yfinance ‡πÑ‡∏î‡πâ")
            sys.exit(1)

# ‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏¥‡∏°‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
data_list = []
for ticker, ticker_data in data_dict.items():
    if ticker_data.empty:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {ticker}")
        continue
    
    # ‚úÖ Reindex ‡πÄ‡∏õ‡πá‡∏ô freq='D' ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ Rolling Mean
    ticker_data = impute_holiday_data(ticker_data, window=3)
    stock_name = ticker.replace('.BK', '')
    ticker_data['Ticker'] = stock_name
    
    # ‚úÖ ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
    for date in ticker_data.index:
        if is_holiday(date, trading_days):
            print(f"‚ö†Ô∏è Note: Data for {ticker} on {date.strftime('%Y-%m-%d')} is imputed using Rolling Mean.")

    data_list.append(ticker_data)

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if not data_list:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏î ‡πÜ ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ")
    sys.exit(1)

# ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
cleaned_data = pd.concat(data_list).reset_index()

# ‚úÖ Merge ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sentiment (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå daily_sentiment_summary.csv)
try:
    sentiment_df = pd.read_csv(os.path.join(os.path.dirname(__file__), "thai", "Stock", "daily_sentiment_summary.csv"))
    sentiment_df['Date'] = pd.to_datetime(sentiment_df['Date'])
    sentiment_df = sentiment_df.set_index(['Date', 'Ticker']).reindex(
        pd.MultiIndex.from_product([cleaned_data['Date'].unique(), [t.replace('.BK', '') for t in tickers]], 
                                  names=['Date', 'Ticker'])
    ).reset_index()
    sentiment_df[['net_sentiment_score', 'Sentiment']] = sentiment_df[['net_sentiment_score', 'Sentiment']].ffill()

    cleaned_data = cleaned_data.merge(
        sentiment_df[['Date', 'Ticker', 'net_sentiment_score', 'Sentiment']],
        on=['Date', 'Ticker'],
        how='left'
    )
    print("‚úÖ Merge ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sentiment ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
except FileNotFoundError:
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå daily_sentiment_summary.csv ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£ Merge ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sentiment")
    cleaned_data['net_sentiment_score'] = pd.NA
    cleaned_data['Sentiment'] = pd.NA

# ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
cleaned_data = cleaned_data.rename(columns={
    'index': 'Date',
    'Ticker': 'Ticker',
    'Open': 'Open',
    'High': 'High',
    'Low': 'Low',
    'Close': 'Close',
    'Volume': 'Volume',
    'Changepercent': 'Changepercent'
})

cleaned_data['Date'] = pd.to_datetime(cleaned_data['Date']).dt.strftime('%Y-%m-%d')

# ‚úÖ ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
columns_to_keep = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume', 'Changepercent', 'net_sentiment_score', 'Sentiment']
cleaned_data = cleaned_data[columns_to_keep]

# ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
print("üîπ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏≠‡∏Å...")
before_filter = len(cleaned_data)
cleaned_data = cleaned_data[
    (cleaned_data['Open'] > 0) &
    (cleaned_data['High'] > 0) &
    (cleaned_data['Low'] > 0) &
    (cleaned_data['Close'] > 0) &
    (cleaned_data['Open'].notna()) &
    (cleaned_data['High'].notna()) &
    (cleaned_data['Low'].notna()) &
    (cleaned_data['Close'].notna())
]
after_filter = len(cleaned_data)
print(f"üîπ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß: {before_filter} -> {after_filter} ‡πÅ‡∏ñ‡∏ß")

# ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥
cleaned_data = cleaned_data.sort_values(['Date', 'Ticker']).reset_index(drop=True)
cleaned_data = cleaned_data.drop_duplicates(subset=['Date', 'Ticker'], keep='first')

# ‚úÖ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
today = datetime.datetime.today().strftime('%Y-%m-%d')
initial_rows = len(cleaned_data)
cleaned_data = cleaned_data[cleaned_data['Date'].astype(str) != today]
if len(cleaned_data) < initial_rows:
    print(f"üîπ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ({today}) ‡πÅ‡∏•‡πâ‡∏ß")

# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV
csv_path = os.path.join(CURRENT_DIR, "thai", "Stock", "stock_data_thai.csv")
os.makedirs(os.path.dirname(csv_path), exist_ok=True)
cleaned_data.to_csv(csv_path, index=False)
print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {csv_path}")

# ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print(f"üîπ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(cleaned_data)} ‡πÅ‡∏ñ‡∏ß")
print(f"üîπ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {cleaned_data['Date'].nunique()} ‡∏ß‡∏±‡∏ô")
if not cleaned_data.empty:
    print(f"üîπ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {cleaned_data['Date'].min()} ‡∏ñ‡∏∂‡∏á {cleaned_data['Date'].max()}")
    for ticker in cleaned_data['Ticker'].unique():
        ticker_data = cleaned_data[cleaned_data['Ticker'] == ticker]
        print(f"üîπ {ticker}: {len(ticker_data)} ‡πÅ‡∏ñ‡∏ß, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î {ticker_data['Date'].max()}")
    print("\nüìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    print(cleaned_data.head(10))
else:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
print("\n‚ö†Ô∏è Warning: This data includes imputed prices for non-trading days (e.g., weekends, holidays) using a 3-day Rolling Mean, as required by the LSTM/GRU model trained with freq='D'. Use with caution for real-world trading decisions.")