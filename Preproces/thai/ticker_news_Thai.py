import spacy
from spacy.tokens import Span
from tqdm import tqdm
import pandas as pd
import time
import os
import io
import sys

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

if not spacy.prefer_gpu():
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GPU ‡∏´‡∏£‡∏∑‡∏≠ spaCy ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GPU")
else:
    print("üöÄ ‡πÉ‡∏ä‡πâ GPU:", spacy.prefer_gpu())


# ‚úÖ ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢)
stock_entities = {
    "ADVANC": ["ADVANC", "AIS"],
    "DIF": ["DIF"],
    "DITTO": ["DITTO"],
    "HUMAN": ["HUMAN"],
    "INET": ["INET"],
    "INSET": ["INSET"],
    "INTUCH": ["INTUCH"],
    "JAS": ["JAS"],
    "JMART": ["JMART"],
    "TRUE": ["TRUE"]
}

# ‚úÖ Context Keyword Mapping (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• keyword ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ)
context_mapping = [
    {"Keywords": ["mobile", "5G", "network", "internet", "broadband", "AIS", "cellular", "telecom"], "Stocks": ["ADVANC"]},
    {"Keywords": ["infrastructure fund", "telecom assets", "tower lease", "fiber optic"], "Stocks": ["DIF"]},
    {"Keywords": ["digital", "document", "scanner", "workflow", "e-document", "digital solution"], "Stocks": ["DITTO"]},
    {"Keywords": ["human resource", "HR software", "payroll", "recruitment", "employee management"], "Stocks": ["HUMAN"]},
    {"Keywords": ["cloud", "data center", "IT service", "hosting", "cloud solution", "server"], "Stocks": ["INET"]},
    {"Keywords": ["network service", "fiber optic", "infrastructure", "installation service"], "Stocks": ["INSET"]},
    {"Keywords": ["investment", "holding company", "telecom", "AIS", "INTUCH group"], "Stocks": ["INTUCH"]},
    {"Keywords": ["broadband", "fixed internet", "telecom", "Jasmine", "fiber"], "Stocks": ["JAS"]},
    {"Keywords": ["retail", "mobile store", "finance service", "Jaymart", "consumer loan", "mobile retail"], "Stocks": ["JMART"]},
    {"Keywords": ["mobile", "5G", "network", "broadband", "TRUE ID", "telecom", "True Corporation"], "Stocks": ["TRUE"]}
]


# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î spaCy Transformer Model
nlp = spacy.load("en_core_web_trf")
print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Entity Ruler
ruler = nlp.add_pipe("entity_ruler", before="ner")
patterns = []
for stock, keywords in stock_entities.items():
    for keyword in keywords:
        patterns.append({
            "label": "ORG",
            "pattern": keyword,
            "id": stock
        })
ruler.add_patterns(patterns)

# ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πà‡∏≤‡∏ß
floder_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'thai', 'News')
file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'thai', 'News', 'Thai_News.csv')
df = pd.read_csv(file_path)

# ‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
texts = df.apply(lambda row: f"{row.get('title', '')} {row.get('description', '')}", axis=1)

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
def process_news(docs):
    results = []
    for doc in docs:
        matched = set()
        # NER
        for ent in doc.ents:
            if ent.label_ == "ORG" and ent.ent_id_:
                matched.add(ent.ent_id_)
        # Context
        text = doc.text.lower()
        for ctx in context_mapping:
            for keyword in ctx["Keywords"]:
                if keyword.lower() in text:
                    matched.update(ctx["Stocks"])
                    break
        results.append(", ".join(sorted(matched)) if matched else None)
    return results

# ‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
start_time = time.time()
batch_size = 10

print(f"üîç ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• NER + Context (Batch size = {batch_size})")
results = []
for doc_batch in tqdm(nlp.pipe(texts, batch_size=batch_size), total=len(texts), desc="üîç Hybrid Processing"):
    results.extend(process_news([doc_batch]))

df["MatchedStock"] = results

# ‚úÖ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
total_news = len(df)
related_df = df[df["MatchedStock"].notnull()]
unrelated_df = df[df["MatchedStock"].isnull()]
related_news = len(related_df)
unrelated_news = len(unrelated_df)
percentage = (related_news / total_news) * 100

end_time = time.time()
elapsed = end_time - start_time

print("\nüìä Hybrid Model Summary")
print(f"‚úÖ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_news}")
print(f"‚úÖ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {related_news} ({percentage:.2f}%)")
print(f"‚úÖ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {unrelated_news} ({100 - percentage:.2f}%)")
print(f"‚è±Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {elapsed / 60:.2f} ‡∏ô‡∏≤‡∏ó‡∏µ\n")

# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
related_path = os.path.join(floder_path, 'Related_News_Hybrid.csv')
unrelated_path = os.path.join(floder_path, 'Unrelated_News_Hybrid.csv')
related_df.to_csv(related_path, index=False, encoding='utf-8')
unrelated_df.to_csv(unrelated_path, index=False, encoding='utf-8')

print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà: Related_News_Hybrid.csv")
print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà: Unrelated_News_Hybrid.csv")
