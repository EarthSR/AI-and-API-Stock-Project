import pandas as pd
import numpy as np
import tensorflow as tf
import tensorflow.keras.backend as K
import tensorflow_addons as tfa
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import (
    Input, LSTM, Dense, Dropout,BatchNormalization, Embedding,
    concatenate, Bidirectional, Layer, Masking, Conv1D, Flatten,
    Attention, MultiHeadAttention, Add, LayerNormalization, Multiply,
    GlobalAveragePooling1D, GlobalMaxPooling1D, Lambda
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import Huber, MeanSquaredError, BinaryCrossentropy
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger
from tensorflow.keras.optimizers.schedules import CosineDecay, ExponentialDecay
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.metrics import (
    mean_absolute_error, mean_squared_error, r2_score,
    accuracy_score, f1_score, precision_score, recall_score
)
import ta
import matplotlib.pyplot as plt
import joblib
import logging
from tensorflow.keras.losses import Loss
from tensorflow.keras.saving import register_keras_serializable
from tensorflow.keras.layers import TimeDistributed
from sklearn.utils.class_weight import compute_class_weight
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

import tensorflow as tf
print("TensorFlow running on:", tf.config.list_physical_devices())

# ------------------------------------------------------------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Error / Custom Loss
# ------------------------------------------------------------------------------------
def custom_mape(y_true, y_pred):
    """
    Mean Absolute Percentage Error (MAPE) ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î Infinity ‡∏ñ‡πâ‡∏≤ y_true = 0
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    nonzero_mask = y_true != 0
    if not np.any(nonzero_mask):
        return np.nan
    return np.mean(np.abs((y_true[nonzero_mask] - y_pred[nonzero_mask]) / y_true[nonzero_mask])) * 100

def focal_loss_fixed(y_true, y_pred, gamma=2.0, alpha=0.25):
    y_true = tf.cast(y_true, tf.float32)
    epsilon = tf.keras.backend.epsilon()
    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)
    loss = -alpha * (y_true * tf.math.pow(1 - y_pred, gamma) * tf.math.log(y_pred)) \
           - (1 - alpha) * ((1 - y_true) * tf.math.pow(y_pred, gamma) * tf.math.log(1 - y_pred))
    return tf.reduce_mean(loss)

def softmax_axis1(x):
    return tf.keras.activations.softmax(x, axis=1)

def smape(y_true, y_pred):
    """
    Symmetric Mean Absolute Percentage Error (sMAPE)
    """
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    diff = np.abs(y_true - y_pred)
    nonzero_mask = denominator != 0
    if not np.any(nonzero_mask):
        return np.nan
    return np.mean(diff[nonzero_mask] / denominator[nonzero_mask]) * 100

def focal_loss(alpha=0.25, gamma=2.0):
    def focal_loss_fixed(y_true, y_pred):
        epsilon = 1e-8
        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)
        pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)
        loss = -K.mean(alpha * K.pow(1. - pt, gamma) * K.log(pt))
        return loss
    return focal_loss_fixed


def cosine_similarity_loss(y_true, y_pred):
    y_true = tf.keras.backend.l2_normalize(y_true, axis=-1)
    y_pred = tf.keras.backend.l2_normalize(y_pred, axis=-1)
    return -tf.reduce_mean(y_true * y_pred)

# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Optimizer ‡πÄ‡∏õ‡πá‡∏ô AdamW
from tensorflow.keras.optimizers import AdamW
@register_keras_serializable()
def focal_loss_fixed(y_true, y_pred, alpha=0.25, gamma=2.0):
    epsilon = 1e-8
    y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)
    pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)
    loss = -K.mean(alpha * K.pow(1. - pt, gamma) * K.log(pt))
    return loss

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Logging
logging.basicConfig(level=logging.INFO, filename='training.log', filemode='a',
                    format='%(asctime)s - %(levelname)s - %(message)s')

# ------------------------------------------------------------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Sequence ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Multi-Task
# ------------------------------------------------------------------------------------
def create_sequences_for_ticker(features, ticker_ids, market_ids, targets_price, targets_dir, seq_length=10):
    """
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ 5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£:
      X_features, X_tickers, X_markets, Y_price, Y_dir
    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ Sequence ‡∏¢‡∏≤‡∏ß seq_length
    """
    X_features, X_tickers, X_markets = [], [], []
    Y_price, Y_dir = [], []

    for i in range(len(features) - seq_length):
        X_features.append(features[i : i + seq_length])
        X_tickers.append(ticker_ids[i : i + seq_length])
        X_markets.append(market_ids[i : i + seq_length])
        Y_price.append(targets_price[i + seq_length])
        Y_dir.append(targets_dir[i + seq_length])

    return (
        np.array(X_features),
        np.array(X_tickers),
        np.array(X_markets),
        np.array(Y_price),
        np.array(Y_dir),
    )

def plot_training_history(history):
    keys = list(history.history.keys())
    print("Keys in history:", keys)

    plt.figure(figsize=(14, 6))
    
    # Subplot 1: Total Loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Total Loss')
    plt.plot(history.history['val_loss'], label='Val Total Loss')
    plt.title('Total Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ subplot ‡πÅ‡∏£‡∏Å
    plt.tight_layout()
    plt.savefig('training_total_loss.png')
    plt.close()

def plot_predictions(y_true, y_pred, ticker):
    plt.figure(figsize=(10, 6))
    plt.plot(y_true, label='Actual', color='blue')
    plt.plot(y_pred, label='Predicted', color='red', alpha=0.7)
    plt.title(f'True vs Predicted Prices for {ticker}')
    plt.xlabel('Time')
    plt.ylabel('Price')
    plt.legend()
    plt.tight_layout()
    plt.savefig(f'predictions_{ticker}.png')
    plt.close()

def plot_residuals(y_true, y_pred, ticker):
    residuals = np.array(y_true) - np.array(y_pred)
    plt.figure(figsize=(10, 6))
    plt.scatter(range(len(residuals)), residuals, alpha=0.5)
    plt.hlines(y=0, xmin=0, xmax=len(residuals), colors='red')
    plt.title(f'Residuals for {ticker}')
    plt.xlabel('Sample')
    plt.ylabel('Residual')
    plt.tight_layout()
    plt.savefig(f'residuals_{ticker}.png')
    plt.close()

def cosine_similarity_loss(y_true, y_pred):
    y_true = K.cast(y_true, dtype=tf.float32)
    y_pred = K.cast(y_pred, dtype=tf.float32)
    y_true = K.l2_normalize(y_true + K.epsilon(), axis=-1)
    y_pred = K.l2_normalize(y_pred + K.epsilon(), axis=-1)
    return -K.mean(y_true * y_pred)

tf.keras.utils.get_custom_objects()["cosine_similarity_loss"] = cosine_similarity_loss

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
physical_devices = tf.config.list_physical_devices('GPU')
if len(physical_devices) > 0:
    tf.config.set_visible_devices(physical_devices[0], 'GPU')
    try:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
        logging.info(f"Memory growth enabled for GPU: {physical_devices[0]}")
        print("Memory growth enabled for GPU:", physical_devices[0])
    except Exception as e:
        logging.error(f"Failed to set memory growth: {e}")
        print(f"Error setting memory growth: {e}")
else:
    logging.info("GPU not found, using CPU")
    print("GPU not found, using CPU")

# ------------------------------------------------------------------------------------
# 1) ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ------------------------------------------------------------------------------------
# df = pd.read_csv('../LSTM_Model/merged_stock_sentiment_financial.csv')
# df = pd.read_csv('../Preproces/merged_stock_sentiment_financial_database.csv')
df = pd.read_csv('../Preproces/data/Stock/merged_stock_sentiment_financial.csv')

df['Sentiment'] = df['Sentiment'].map({'Positive': 1, 'Negative': -1, 'Neutral': 0})
df['Change'] = df['Close'] - df['Open']
df['Change (%)'] = df.groupby('Ticker')['Close'].pct_change() * 100
upper_bound = df['Change (%)'].quantile(0.99)
lower_bound = df['Change (%)'].quantile(0.01)
df['Change (%)'] = df['Change (%)'].clip(lower_bound, upper_bound)

df['RSI'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()
# ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà fillna(0) ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á
df['RSI'] = df.groupby('Ticker')['RSI'].transform(lambda x: x.fillna(x.rolling(window=5, min_periods=1).mean()))
df['EMA_12'] = df.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())
df['EMA_26'] = df.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())
df['EMA_10'] = df.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=10, adjust=False).mean())
df['EMA_20'] = df.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=20, adjust=False).mean())
df['SMA_50'] = df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=50).mean())
df['SMA_200'] = df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=200).mean())
df['MACD'] = df['EMA_12'] - df['EMA_26']
df['MACD_Signal'] = df.groupby('Ticker')['MACD'].transform(lambda x: x.rolling(window=9).mean())

bollinger = ta.volatility.BollingerBands(df['Close'], window=20, window_dev=2)
df['Bollinger_High'] = bollinger.bollinger_hband()
df['Bollinger_Low'] = bollinger.bollinger_lband()

atr = ta.volatility.AverageTrueRange(high=df['High'], low=df['Low'], close=df['Close'], window=14)
df['ATR'] = atr.average_true_range()

keltner = ta.volatility.KeltnerChannel(high=df['High'], low=df['Low'], close=df['Close'], window=20, window_atr=10)
df['Keltner_High'] = keltner.keltner_channel_hband()
df['Keltner_Low'] = keltner.keltner_channel_lband()
df['Keltner_Middle'] = keltner.keltner_channel_mband()

window_cv = 10
df['High_Low_Diff'] = df['High'] - df['Low']
df['High_Low_EMA'] = df.groupby('Ticker')['High_Low_Diff'].transform(lambda x: x.ewm(span=window_cv, adjust=False).mean())
df['Chaikin_Vol'] = df.groupby('Ticker')['High_Low_EMA'].transform(lambda x: x.pct_change(periods=window_cv) * 100)

window_dc = 20
df['Donchian_High'] = df.groupby('Ticker')['High'].transform(lambda x: x.rolling(window=window_dc).max())
df['Donchian_Low'] = df.groupby('Ticker')['Low'].transform(lambda x: x.rolling(window=window_dc).min())

psar = ta.trend.PSARIndicator(high=df['High'], low=df['Low'], close=df['Close'], step=0.02, max_step=0.2)
df['PSAR'] = psar.psar()

us_stock = ['AAPL', 'NVDA', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'AVGO', 'TSM', 'AMD']
thai_stock = ['ADVANC', 'TRUE', 'DITTO', 'DIF', 
           'INSET', 'JMART', 'INET', 'JAS', 'HUMAN']
df['Market_ID'] = df['Ticker'].apply(lambda x: "US" if x in us_stock else "TH" if x in thai_stock else None)

financial_columns = [
    'Total Revenue', 'QoQ Growth (%)', 'Earnings Per Share (EPS)', 'ROE (%)',
    'Net Profit Margin (%)', 'Debt to Equity', 'P/E Ratio',
    'P/BV Ratio', 'Dividend Yield (%)'
]
df_financial = df[['Date', 'Ticker'] + financial_columns].drop_duplicates()
df_financial[financial_columns] = df_financial[financial_columns].where(df_financial[financial_columns].ne(0)).bfill()

# ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ stock_columns
stock_columns = [
    'RSI', 'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'Bollinger_High',
    'Bollinger_Low', 'ATR', 'Keltner_High', 'Keltner_Low', 'Keltner_Middle',
    'Chaikin_Vol', 'Donchian_High', 'Donchian_Low', 'PSAR', 'SMA_50', 'SMA_200'
]
df[stock_columns] = df[stock_columns].fillna(method='ffill')
df.fillna(0, inplace=True)

feature_columns = [
    'Open', 'High', 'Low', 'Close', 'Volume', 'Change (%)', 'Sentiment','positive_news','negative_news','neutral_news',
    'Total Revenue', 'QoQ Growth (%)','Earnings Per Share (EPS)','ROE (%)',
    'ATR','Keltner_High','Keltner_Low','Keltner_Middle','Chaikin_Vol','Donchian_High','Donchian_Low','PSAR',
    'Net Profit Margin (%)', 'Debt to Equity', 'P/E Ratio',
    'P/BV Ratio', 'Dividend Yield (%)','RSI', 'EMA_10', 'EMA_20', 'MACD', 'MACD_Signal',
    'Bollinger_High', 'Bollinger_Low','SMA_50', 'SMA_200'
]
joblib.dump(feature_columns, 'feature_columns.pkl')

# ‡∏™‡∏£‡πâ‡∏≤‡∏á target variables
df['Direction'] = (df['Close'].shift(-1) > df['Close']).astype(int)
df['TargetPrice'] = df['Close'].shift(-1)

df.dropna(subset=['Direction', 'TargetPrice'], inplace=True)

# Encode categorical variables
market_encoder = LabelEncoder()
df['Market_ID'] = market_encoder.fit_transform(df['Market_ID'])
num_markets = len(market_encoder.classes_)
joblib.dump(market_encoder, 'market_encoder.pkl')

ticker_encoder = LabelEncoder()
df['Ticker_ID'] = ticker_encoder.fit_transform(df['Ticker'])
num_tickers = len(ticker_encoder.classes_)
joblib.dump(ticker_encoder, 'ticker_encoder.pkl')

# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/test
sorted_dates = df['Date'].unique()
train_cutoff = sorted_dates[int(len(sorted_dates) * 6 / 7)]
train_df = df[df['Date'] <= train_cutoff].copy()
test_df = df[df['Date'] > train_cutoff].copy()

train_df.to_csv('train_df.csv', index=False)
test_df.to_csv('test_df.csv', index=False)
print("Train cutoff:", train_cutoff)
print("First date in train set:", train_df['Date'].min())
print("Last date in train set:", train_df['Date'].max())

# ------------------------------------------------------------------------------------
# 2) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Target (Price, Direction) + Per-Ticker Scaling
# ------------------------------------------------------------------------------------
train_features = train_df[feature_columns].values
test_features  = test_df[feature_columns].values

train_features[train_features == np.inf] = np.max(train_features[train_features != np.inf])
train_features[train_features == -np.inf] = np.min(train_features[train_features != -np.inf])

train_ticker_id = train_df['Ticker_ID'].values
train_market_id = train_df['Market_ID'].values
test_ticker_id  = test_df['Ticker_ID'].values
test_market_id  = test_df['Market_ID'].values

train_price = train_df['TargetPrice'].values.reshape(-1, 1)
test_price  = test_df['TargetPrice'].values.reshape(-1, 1)

train_dir = train_df['Direction'].values
test_dir  = test_df['Direction'].values

train_features_scaled = np.zeros_like(train_features)
train_price_scaled    = np.zeros_like(train_price)
test_features_scaled  = np.zeros_like(test_features)
test_price_scaled     = np.zeros_like(test_price)

ticker_scalers = {}

unique_tickers_train = train_df['Ticker_ID'].unique()

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Ticker_ID ‡∏Å‡∏±‡∏ö StockSymbol
ticker_id_to_name = {}
for t_id in unique_tickers_train:
    ticker_rows = train_df[train_df['Ticker_ID'] == t_id]
    ticker_name = ticker_rows['Ticker'].iloc[0]
    ticker_id_to_name[t_id] = ticker_name
    print(f"Mapping: Ticker_ID {t_id} = {ticker_name}")

for t_id in unique_tickers_train:
    mask_train = (train_ticker_id == t_id)
    X_part = train_features[mask_train]
    y_part = train_price[mask_train]

    scaler_f = RobustScaler()
    scaler_p = RobustScaler()

    X_scaled = scaler_f.fit_transform(X_part)
    y_scaled = scaler_p.fit_transform(y_part)

    train_features_scaled[mask_train] = X_scaled
    train_price_scaled[mask_train]    = y_scaled

    # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° 'ticker' key ‡πÉ‡∏´‡πâ compatible ‡∏Å‡∏±‡∏ö Online Learning
    ticker_scalers[t_id] = {
        'feature_scaler': scaler_f,
        'price_scaler': scaler_p,
        'ticker': ticker_id_to_name[t_id]  # ‚Üê ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ!
    }

unique_tickers_test = test_df['Ticker_ID'].unique()
for t_id in unique_tickers_test:
    if t_id not in ticker_scalers:
        print(f"Ticker {t_id} not found in training scalers. Skipping.")
        continue
    mask_test = (test_ticker_id == t_id)
    X_part = test_features[mask_test]
    y_part = test_price[mask_test]

    scaler_f = ticker_scalers[t_id]['feature_scaler']
    scaler_p = ticker_scalers[t_id]['price_scaler']

    X_scaled = scaler_f.transform(X_part)
    y_scaled = scaler_p.transform(y_part)

    test_features_scaled[mask_test] = X_scaled
    test_price_scaled[mask_test]    = y_scaled

# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ticker_scalers ‡∏ó‡∏µ‡πà‡∏°‡∏µ 'ticker' key
joblib.dump(ticker_scalers, 'ticker_scalers.pkl')
np.save('test_features.npy', test_features_scaled)
np.save('test_price.npy',   test_price_scaled)
np.save('train_features.npy', train_features_scaled)
np.save('train_price.npy',   train_price_scaled)
print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ticker_scalers.pkl ‡∏û‡∏£‡πâ‡∏≠‡∏° ticker names ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

# ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ticker_scalers ‡πÄ‡∏û‡∏∑‡πà‡∏≠ verify
print(f"\nüìä Ticker Scalers Summary:")
for t_id, scaler_info in ticker_scalers.items():
    ticker_name = scaler_info.get('ticker', 'Unknown')
    print(f"   Ticker_ID {t_id}: {ticker_name}")

seq_length = 10

# ------------------------------------------------------------------------------------
# 3) ‡∏™‡∏£‡πâ‡∏≤‡∏á Sequence (‡∏ï‡πà‡∏≠ Ticker) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Multi-Task (Price + Direction)
# ------------------------------------------------------------------------------------
X_train_list, X_train_ticker_list, X_train_market_list = [], [], []
y_price_train_list, y_dir_train_list = [], []

X_test_list, X_test_ticker_list, X_test_market_list = [], [], []
y_price_test_list, y_dir_test_list = [], []

for t_id in range(num_tickers):
    df_train_ticker = train_df[train_df['Ticker_ID'] == t_id]
    if len(df_train_ticker) > seq_length:
        idx_train = df_train_ticker.index
        mask_train = np.isin(train_df.index, idx_train)

        f_t = train_features_scaled[mask_train]
        t_t = train_ticker_id[mask_train]
        m_t = train_market_id[mask_train]
        p_t = train_price_scaled[mask_train]
        d_t = train_dir[mask_train]

        (Xf, Xt, Xm, Yp, Yd) = create_sequences_for_ticker(
            f_t, t_t, m_t, p_t, d_t, seq_length
        )
        X_train_list.append(Xf)
        X_train_ticker_list.append(Xt)
        X_train_market_list.append(Xm)
        y_price_train_list.append(Yp)
        y_dir_train_list.append(Yd)

    df_test_ticker = test_df[test_df['Ticker_ID'] == t_id]
    if len(df_test_ticker) > seq_length:
        idx_test = df_test_ticker.index
        mask_test = np.isin(test_df.index, idx_test)

        f_s = test_features_scaled[mask_test]
        t_s = test_ticker_id[mask_test]
        m_s = test_market_id[mask_test]
        p_s = test_price_scaled[mask_test]
        d_s = test_dir[mask_test]

        (Xs, Xts, Xms, Yps, Yds) = create_sequences_for_ticker(
            f_s, t_s, m_s, p_s, d_s, seq_length
        )
        X_test_list.append(Xs)
        X_test_ticker_list.append(Xts)
        X_test_market_list.append(Xms)
        y_price_test_list.append(Yps)
        y_dir_test_list.append(Yds)

if len(X_train_list) > 0:
    X_price_train = np.concatenate(X_train_list, axis=0)
    X_ticker_train = np.concatenate(X_train_ticker_list, axis=0)
    X_market_train = np.concatenate(X_train_market_list, axis=0)
    y_price_train = np.concatenate(y_price_train_list, axis=0)
    y_dir_train   = np.concatenate(y_dir_train_list, axis=0)
else:
    X_price_train, X_ticker_train, X_market_train, y_price_train, y_dir_train = (np.array([]),)*5

if len(X_test_list) > 0:
    X_price_test = np.concatenate(X_test_list, axis=0)
    X_ticker_test = np.concatenate(X_test_ticker_list, axis=0)
    X_market_test = np.concatenate(X_test_market_list, axis=0)
    y_price_test  = np.concatenate(y_price_test_list, axis=0)
    y_dir_test    = np.concatenate(y_dir_test_list, axis=0)
else:
    X_price_test, X_ticker_test, X_market_test, y_price_test, y_dir_test = (np.array([]),)*5

print("X_price_train shape :", X_price_train.shape)
print("X_ticker_train shape:", X_ticker_train.shape)
print("y_price_train shape :", y_price_train.shape)
print("y_dir_train shape   :", y_dir_train.shape)

num_feature = train_features_scaled.shape[1]

# ------------------------------------------------------------------------------------
# V6+ MINIMAL TUNING V2 - FINAL WINNER MODEL
# ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: MAE 5.81, Direction Acc 62.43%, ‡πÑ‡∏°‡πà‡∏°‡∏µ R¬≤ ‡∏ï‡∏¥‡∏î‡∏•‡∏ö
# ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: MAE < 6.20, Direction Acc > 60%, ‡πÑ‡∏°‡πà‡∏°‡∏µ R¬≤ ‡∏ï‡∏¥‡∏î‡∏•‡∏ö
# ------------------------------------------------------------------------------------

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import *
from tensorflow.keras.optimizers import AdamW
from tensorflow.keras.optimizers.schedules import CosineDecay
from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# ------------------------------------------------------------------------------------
# V6+ ORIGINAL LOSS FUNCTIONS (‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
# ------------------------------------------------------------------------------------

@tf.keras.utils.register_keras_serializable()
def quantile_loss(y_true, y_pred, quantile=0.5):
    error = y_true - y_pred
    return tf.keras.backend.mean(tf.keras.backend.maximum(quantile * error, (quantile - 1) * error))

def focal_weighted_binary_crossentropy(class_weights, gamma=2.0, alpha_pos=0.7):
    def loss(y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        epsilon = 1e-7
        y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)
        
        weights = tf.where(y_true == 1, class_weights[1], class_weights[0])
        alpha = tf.where(y_true == 1, alpha_pos, 1 - alpha_pos)
        pt = tf.where(y_true == 1, y_pred, 1 - y_pred)
        focal_factor = tf.pow(1 - pt, gamma)
        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
        weighted_bce = bce * weights * alpha * focal_factor
        return tf.reduce_mean(weighted_bce)
    return loss

# ------------------------------------------------------------------------------------
# CLASS WEIGHTS
# ------------------------------------------------------------------------------------

class_weights = compute_class_weight('balanced', classes=np.unique(y_dir_train), y=y_dir_train)
class_weight_dict = {0: tf.cast(class_weights[0], tf.float32), 1: tf.cast(class_weights[1], tf.float32)}
print("V6+ Minimal Tuning V2 Final Class Weights:", class_weight_dict)

# ------------------------------------------------------------------------------------
# V6+ MINIMAL TUNING V2 MODEL ARCHITECTURE
# ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
# ------------------------------------------------------------------------------------

# Input layers (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
features_input = Input(shape=(seq_length, num_feature), name='features_input')
ticker_input = Input(shape=(seq_length,), name='ticker_input')
market_input = Input(shape=(seq_length,), name='market_input')

# Ticker Embedding (‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°: 33)
embedding_dim = 33
ticker_embedding = Embedding(
    input_dim=num_tickers,
    output_dim=embedding_dim,
    embeddings_regularizer=tf.keras.regularizers.l2(1e-7),
    name="ticker_embedding"
)(ticker_input)
ticker_embedding = Dense(16, activation="relu")(ticker_embedding)

# Market Embedding (‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)
embedding_dim_market = 8
market_embedding = Embedding(
    input_dim=num_markets,
    output_dim=embedding_dim_market,
    embeddings_regularizer=tf.keras.regularizers.l2(1e-7),
    name="market_embedding"
)(market_input)
market_embedding = Dense(8, activation="relu")(market_embedding)

# Merge all inputs
merged = concatenate([features_input, ticker_embedding, market_embedding], axis=-1)

# LSTM Backbone (‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
x = Bidirectional(LSTM(65, return_sequences=True, dropout=0.21, recurrent_dropout=0.15))(merged)
x = Dropout(0.21)(x)
x = Bidirectional(LSTM(32, return_sequences=False, dropout=0.21, recurrent_dropout=0.15))(x)
x = Dropout(0.21)(x)

# Shared representation layer (‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß)
shared_repr = Dense(66, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(1e-6))(x)

# Price prediction head (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡πÅ‡∏•‡πâ‡∏ß)
price_head = Dense(32, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(1e-6))(shared_repr)
price_head = Dropout(0.22)(price_head)
price_output = Dense(1, name="price_output")(price_head)

# Direction prediction head (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡πÅ‡∏•‡πâ‡∏ß)
dir_head = Dense(32, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(1e-6))(shared_repr)
dir_head = Dropout(0.22)(dir_head)
direction_output = Dense(1, activation="sigmoid", name="direction_output")(dir_head)

# Create model
model = Model(
    inputs=[features_input, ticker_input, market_input],
    outputs=[price_output, direction_output]
)

# ------------------------------------------------------------------------------------
# PROVEN TRAINING CONFIGURATION
# ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
# ------------------------------------------------------------------------------------

# Training parameters (‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏™‡∏π‡∏à‡∏ô‡πå‡πÅ‡∏•‡πâ‡∏ß)
batch_size = 33
validation_split = 0.12
expected_epochs = 105
train_size = int(len(X_price_train) * (1 - validation_split))
steps_per_epoch = train_size // batch_size
decay_steps = steps_per_epoch * expected_epochs * 1.4

# Learning Rate Schedule (‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå‡∏ô‡∏¥‡∏¢‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
lr_schedule = CosineDecay(
    initial_learning_rate=1.7e-4,
    decay_steps=decay_steps,
    alpha=9e-6
)

# Optimizer (‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
optimizer = AdamW(
    learning_rate=lr_schedule,
    weight_decay=1.4e-5,
    clipnorm=0.95
)

# Compile model (loss weights ‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß)
model.compile(
    optimizer=optimizer,
    loss={
        "price_output": tf.keras.losses.Huber(delta=0.75),
        "direction_output": focal_weighted_binary_crossentropy(class_weight_dict, gamma=1.95)
    },
    loss_weights={"price_output": 0.39, "direction_output": 0.61},
    metrics={
        "price_output": [tf.keras.metrics.MeanAbsoluteError()],
        "direction_output": [tf.keras.metrics.BinaryAccuracy()]
    }
)

# Print model summary
print("\nüèÜ V6+ Minimal Tuning V2 Final Model Summary:")
model.summary()
print(f"\nüéØ Total Parameters: {model.count_params():,}")

# ------------------------------------------------------------------------------------
# PROVEN CALLBACKS
# Callback ‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ
# ------------------------------------------------------------------------------------

# Early Stopping (‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)
early_stopping = EarlyStopping(
    monitor="val_loss",
    patience=20,
    restore_best_weights=True,
    verbose=1,
    min_delta=1.2e-4,
    start_from_epoch=12
)

# Learning Rate Scheduler (‡∏≠‡∏ô‡∏∏‡∏£‡∏±‡∏Å‡∏©‡πå‡∏ô‡∏¥‡∏¢‡∏°)
lr_scheduler = ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.68,
    patience=7,
    min_lr=1.2e-7,
    verbose=1,
    cooldown=3
)

# Model Checkpoint
checkpoint = ModelCheckpoint(
    "best_v6_plus_minimal_tuning_v2_final_model.keras",
    monitor="val_loss",
    save_best_only=True,
    mode="min",
    verbose=1
)

# CSV Logger
csv_logger = CSVLogger('v6_plus_minimal_tuning_v2_final_training_log.csv')

# Stability callback
class StabilityCallback(tf.keras.callbacks.Callback):
    def __init__(self):
        super().__init__()
        self.best_combined_score = float('inf')
    
    def on_epoch_end(self, epoch, logs=None):
        val_mae = logs.get('val_price_output_mean_absolute_error', 0)
        val_acc = logs.get('val_direction_output_binary_accuracy', 0)
        
        # Combined score prioritizing stability
        combined_score = val_mae * 2 + (1 - val_acc) * 1.5
        
        if epoch % 8 == 0:
            print(f"\nüìä Epoch {epoch}: Val MAE={val_mae:.4f}, Val Acc={val_acc:.4f}")
            print(f"   Combined Score: {combined_score:.4f} (Lower is better)")
            
        if combined_score < self.best_combined_score:
            self.best_combined_score = combined_score
            print(f"   üéØ New best combined score: {combined_score:.4f}")

stability_callback = StabilityCallback()

# Combine callbacks
callbacks = [early_stopping, lr_scheduler, checkpoint, csv_logger, stability_callback]

# ------------------------------------------------------------------------------------
# TRAINING CONFIGURATION
# ------------------------------------------------------------------------------------

# Calculate class weights for direction prediction
print("üìä Computing class weights for direction prediction...")
direction_classes = np.unique(y_dir_train)
class_weights_array = compute_class_weight(
    'balanced',
    classes=direction_classes,
    y=y_dir_train.flatten()
)
class_weights_dict = dict(zip(direction_classes.astype(int), class_weights_array))

print(f"   Class weights: {class_weights_dict}")
print(f"   Class distribution: {np.bincount(y_dir_train.flatten().astype(int))}")

# Save class weights to file
import pickle
os.makedirs(os.path.dirname('./class_weights.pkl'), exist_ok=True)
with open('class_weights.pkl', 'wb') as f:
    pickle.dump(class_weights_dict, f)
print("üíæ Saved class_weights.pkl")

# Training the model
history = model.fit(
    [X_price_train, X_ticker_train, X_market_train],
    {"price_output": y_price_train, "direction_output": y_dir_train},
    epochs=expected_epochs,
    batch_size=batch_size,
    verbose=1,
    shuffle=False,
    validation_split=validation_split,
    callbacks=callbacks
)

# ------------------------------------------------------------------------------------
# MODEL LOADING AND EVALUATION
# ------------------------------------------------------------------------------------

# Load the best trained model
try:
    best_model = tf.keras.models.load_model(
        "best_v6_plus_minimal_tuning_v2_final_model.keras",
        custom_objects={
            "quantile_loss": quantile_loss,
            "focal_weighted_binary_crossentropy": focal_weighted_binary_crossentropy
        },
        safe_mode=False
    )
    print("\n‚úÖ Loaded best V6+ Minimal Tuning V2 Final model successfully!")
except Exception as e:
    print(f"\n‚ö†Ô∏è Could not load best model: {e}")
    best_model = model

# Save training history
import pandas as pd
history_df = pd.DataFrame(history.history)
history_df.to_csv('v6_plus_minimal_tuning_v2_final_training_history.csv', index=False)
print("‚úÖ Saved training history to 'v6_plus_minimal_tuning_v2_final_training_history.csv'")

# Print final results
if history.history:
    final_val_loss = min(history.history['val_loss'])
    final_val_mae = min(history.history['val_price_output_mean_absolute_error'])
    final_val_acc = max(history.history['val_direction_output_binary_accuracy'])
    
    print(f"\nüìä Final V6+ Minimal Tuning V2 Results:")
    print(f"   Best Val Loss: {final_val_loss:.4f}")
    print(f"   Best Val MAE: {final_val_mae:.4f}")
    print(f"   Best Val Direction Acc: {final_val_acc:.4f}")
    print(f"   Total Epochs: {len(history.history['val_loss'])}")

# ------------------------------------------------------------------------------------
# 5) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Walk-Forward Validation (‡πÉ‡∏ä‡πâ Per-Ticker Scaler)
# ------------------------------------------------------------------------------------
def walk_forward_validation_multi_task_batch(
    model,
    df,
    feature_columns,
    ticker_scalers,   # Dict ‡∏Ç‡∏≠‡∏á Scaler per Ticker
    ticker_encoder,
    market_encoder,
    seq_length=10,
    retrain_frequency=5,
    chunk_size = 200
):
    """
    ‡∏ó‡∏≥ Walk-Forward Validation ‡πÅ‡∏ö‡∏ö Multi-Task (Price + Direction)
    ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô chunks ‡∏•‡∏∞ 90 ‡∏ß‡∏±‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏° Online Learning
    
    - Mini-retrain: ‡∏ó‡∏∏‡∏Å retrain_frequency ‡∏ß‡∏±‡∏ô (Online Learning ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á)
    - Chunk-based: ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    """

    all_predictions = []
    chunk_metrics = []
    tickers = df['Ticker'].unique()

    for ticker in tickers:
        print(f"\nProcessing Ticker: {ticker}")
        df_ticker = df[df['Ticker'] == ticker].sort_values('Date').reset_index(drop=True)
        
        total_days = len(df_ticker)
        print(f"   üìä Total data available: {total_days} days")
        
        if total_days < chunk_size + seq_length:
            print(f"   ‚ö†Ô∏è Not enough data (need at least {chunk_size + seq_length} days), skipping...")
            continue
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏î‡πâ
        num_chunks = total_days // chunk_size
        remaining_days = total_days % chunk_size
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° partial chunk ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
        if remaining_days > seq_length:
            num_chunks += 1
            
        print(f"   üì¶ Number of chunks: {num_chunks} (chunk_size={chunk_size})")
        
        ticker_predictions = []
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞ chunk
        for chunk_idx in range(num_chunks):
            start_idx = chunk_idx * chunk_size
            end_idx = min(start_idx + chunk_size, total_days)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î chunk
            if (end_idx - start_idx) < seq_length + 1:
                print(f"      ‚ö†Ô∏è Chunk {chunk_idx + 1} too small ({end_idx - start_idx} days), skipping...")
                continue
                
            current_chunk = df_ticker.iloc[start_idx:end_idx].reset_index(drop=True)
            
            print(f"\n      üì¶ Processing Chunk {chunk_idx + 1}/{num_chunks}")
            print(f"         üìÖ Date range: {current_chunk['Date'].min()} to {current_chunk['Date'].max()}")
            print(f"         üìà Days: {len(current_chunk)} ({start_idx}-{end_idx})")
            
            # === Walk-Forward Validation ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô Chunk ===
            chunk_predictions = []
            batch_features = []
            batch_tickers = []
            batch_market = []
            batch_price = []
            batch_dir = []
            predictions_count = 0

            for i in range(len(current_chunk) - seq_length):
                historical_data = current_chunk.iloc[i : i + seq_length]
                target_data = current_chunk.iloc[i + seq_length]

                t_id = historical_data['Ticker_ID'].iloc[-1]
                if t_id not in ticker_scalers:
                    print(f"         ‚ö†Ô∏è Ticker_ID {t_id} not found in scalers, skipping...")
                    continue

                scaler_f = ticker_scalers[t_id]['feature_scaler']
                scaler_p = ticker_scalers[t_id]['price_scaler']

                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° input features
                features = historical_data[feature_columns].values
                ticker_ids = historical_data['Ticker_ID'].values
                market_ids = historical_data['Market_ID'].values

                try:
                    features_scaled = scaler_f.transform(features)
                except Exception as e:
                    print(f"         ‚ö†Ô∏è Feature scaling error: {e}")
                    continue

                X_features = features_scaled.reshape(1, seq_length, len(feature_columns))
                X_ticker = ticker_ids.reshape(1, seq_length)
                X_market = market_ids.reshape(1, seq_length)

                # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                try:
                    pred_output = model.predict([X_features, X_ticker, X_market], verbose=0)
                    pred_price_scaled = pred_output[0]
                    pred_dir_prob = pred_output[1]

                    predicted_price = scaler_p.inverse_transform(pred_price_scaled)[0][0]
                    predicted_dir = 1 if pred_dir_prob[0][0] >= 0.5 else 0

                    # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                    actual_price = target_data['Close']
                    future_date = target_data['Date']
                    last_close = historical_data.iloc[-1]['Close']
                    actual_dir = 1 if (target_data['Close'] > last_close) else 0

                    chunk_predictions.append({
                        'Ticker': ticker,
                        'Date': future_date,
                        'Chunk_Index': chunk_idx + 1,
                        'Position_in_Chunk': i + 1,
                        'Predicted_Price': predicted_price,
                        'Actual_Price': actual_price,
                        'Predicted_Dir': predicted_dir,
                        'Actual_Dir': actual_dir,
                        'Last_Close': last_close,
                        'Price_Change_Actual': actual_price - last_close,
                        'Price_Change_Predicted': predicted_price - last_close
                    })

                    predictions_count += 1

                    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö mini-retrain
                    batch_features.append(X_features)
                    batch_tickers.append(X_ticker)
                    batch_market.append(X_market)

                    y_price_true_scaled = scaler_p.transform(np.array([[actual_price]], dtype=float))
                    batch_price.append(y_price_true_scaled)

                    y_dir_true = np.array([actual_dir], dtype=float)
                    batch_dir.append(y_dir_true)

                    # üîÑ Mini-retrain (Online Learning ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô chunk)
                    if (i+1) % retrain_frequency == 0 or (i == (len(current_chunk) - seq_length - 1)):
                        if len(batch_features) > 0:
                            try:
                                bf = np.concatenate(batch_features, axis=0)
                                bt = np.concatenate(batch_tickers, axis=0)
                                bm = np.concatenate(batch_market, axis=0)
                                bp = np.concatenate(batch_price, axis=0)
                                bd = np.concatenate(batch_dir, axis=0)

                                model.fit(
                                    [bf, bt, bm],
                                    {
                                        'price_output': bp,
                                        'direction_output': bd
                                    },
                                    epochs=1,
                                    batch_size=len(bf),
                                    verbose=0,
                                    shuffle=False
                                )
                                
                                print(f"            üîÑ Mini-retrain at position {i+1} (batch size: {len(bf)})")
                                
                            except Exception as e:
                                print(f"            ‚ö†Ô∏è Mini-retrain error: {e}")

                            # ‡∏•‡πâ‡∏≤‡∏á batch
                            batch_features = []
                            batch_tickers = []
                            batch_market = []
                            batch_price = []
                            batch_dir = []
                            
                except Exception as e:
                    print(f"         ‚ö†Ô∏è Prediction error at position {i}: {e}")
                    continue

            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chunk ‡∏ô‡∏µ‡πâ
            if chunk_predictions:
                chunk_df = pd.DataFrame(chunk_predictions)
                
                actual_prices = chunk_df['Actual_Price'].values
                pred_prices = chunk_df['Predicted_Price'].values
                actual_dirs = chunk_df['Actual_Dir'].values
                pred_dirs = chunk_df['Predicted_Dir'].values
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics
                mae_val = mean_absolute_error(actual_prices, pred_prices)
                mse_val = mean_squared_error(actual_prices, pred_prices)
                rmse_val = np.sqrt(mse_val)
                r2_val = r2_score(actual_prices, pred_prices)
                dir_acc = accuracy_score(actual_dirs, pred_dirs)
                dir_f1 = f1_score(actual_dirs, pred_dirs)
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MAPE ‡πÅ‡∏•‡∏∞ SMAPE (safe calculation)
                try:
                    mape_val = np.mean(np.abs((actual_prices - pred_prices) / actual_prices)) * 100
                except:
                    mape_val = 0
                    
                try:
                    smape_val = 100/len(actual_prices) * np.sum(2 * np.abs(pred_prices - actual_prices) / (np.abs(actual_prices) + np.abs(pred_prices)))
                except:
                    smape_val = 0

                chunk_metric = {
                    'Ticker': ticker,
                    'Chunk_Index': chunk_idx + 1,
                    'Chunk_Start_Date': current_chunk['Date'].min(),
                    'Chunk_End_Date': current_chunk['Date'].max(),
                    'Chunk_Days': len(current_chunk),
                    'Predictions_Count': predictions_count,
                    'MAE': mae_val,
                    'MSE': mse_val,
                    'RMSE': rmse_val,
                    'MAPE': mape_val,
                    'SMAPE': smape_val,
                    'R2_Score': r2_val,
                    'Direction_Accuracy': dir_acc,
                    'Direction_F1': dir_f1
                }
                
                chunk_metrics.append(chunk_metric)
                ticker_predictions.extend(chunk_predictions)
                
                print(f"         üìä Chunk results: {predictions_count} predictions")
                print(f"         üìà Direction accuracy: {dir_acc:.3f}")
                print(f"         üìà Price MAE: {mae_val:.3f}")
            
            # ‚úÖ ‡πÅ‡∏Ñ‡πà Mini-retrain (Online Learning) ‡∏Å‡πá‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡πÅ‡∏•‡πâ‡∏ß
            print(f"         ‚úÖ Chunk {chunk_idx + 1} completed with continuous online learning")
        
        all_predictions.extend(ticker_predictions)
        print(f"   ‚úÖ Completed {ticker}: {len(ticker_predictions)} total predictions from {num_chunks} chunks")

    # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    print(f"\nüìä Processing complete!")
    print(f"   Total predictions: {len(all_predictions)}")
    print(f"   Total chunks processed: {len(chunk_metrics)}")
    
    if len(all_predictions) == 0:
        print("‚ùå No predictions generated!")
        return pd.DataFrame(), {}

    predictions_df = pd.DataFrame(all_predictions)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å predictions
    predictions_df.to_csv('predictions_chunk_walkforward.csv', index=False)
    print("üíæ Saved predictions to 'predictions_chunk_walkforward.csv'")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å chunk metrics
    if chunk_metrics:
        chunk_metrics_df = pd.DataFrame(chunk_metrics)
        chunk_metrics_df.to_csv('chunk_metrics.csv', index=False)
        print("üíæ Saved chunk metrics to 'chunk_metrics.csv'")

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Overall Metrics ‡∏ï‡πà‡∏≠ Ticker
    print("\nüìä Calculating overall metrics...")
    overall_metrics = {}
    
    for ticker, group in predictions_df.groupby('Ticker'):
        actual_prices = group['Actual_Price'].values
        pred_prices = group['Predicted_Price'].values
        actual_dirs = group['Actual_Dir'].values
        pred_dirs = group['Predicted_Dir'].values

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics
        mae_val = mean_absolute_error(actual_prices, pred_prices)
        mse_val = mean_squared_error(actual_prices, pred_prices)
        rmse_val = np.sqrt(mse_val)
        r2_val = r2_score(actual_prices, pred_prices)

        dir_acc = accuracy_score(actual_dirs, pred_dirs)
        dir_f1 = f1_score(actual_dirs, pred_dirs)
        dir_precision = precision_score(actual_dirs, pred_dirs)
        dir_recall = recall_score(actual_dirs, pred_dirs)

        # Safe MAPE ‡πÅ‡∏•‡∏∞ SMAPE calculation
        try:
            mape_val = np.mean(np.abs((actual_prices - pred_prices) / actual_prices)) * 100
        except:
            mape_val = 0
            
        try:
            smape_val = 100/len(actual_prices) * np.sum(2 * np.abs(pred_prices - actual_prices) / (np.abs(actual_prices) + np.abs(pred_prices)))
        except:
            smape_val = 0

        overall_metrics[ticker] = {
            'Total_Predictions': len(group),
            'Number_of_Chunks': len(group['Chunk_Index'].unique()),
            'MAE': mae_val,
            'MSE': mse_val,
            'RMSE': rmse_val,
            'MAPE': mape_val,
            'SMAPE': smape_val,
            'R2_Score': r2_val,
            'Direction_Accuracy': dir_acc,
            'Direction_F1_Score': dir_f1,
            'Direction_Precision': dir_precision,
            'Direction_Recall': dir_recall
        }

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å overall metrics
    overall_metrics_df = pd.DataFrame.from_dict(overall_metrics, orient='index')
    overall_metrics_df.to_csv('overall_metrics_per_ticker.csv')
    print("üíæ Saved overall metrics to 'overall_metrics_per_ticker.csv'")

    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    print(f"\nüéØ Summary:")
    print(f"   üìà Tickers processed: {len(predictions_df['Ticker'].unique())}")
    print(f"   üìà Average predictions per ticker: {len(predictions_df)/len(predictions_df['Ticker'].unique()):.1f}")
    print(f"   üìà Average chunks per ticker: {len(chunk_metrics)/len(predictions_df['Ticker'].unique()):.1f}")
    
    if chunk_metrics:
        avg_chunk_acc = np.mean([c['Direction_Accuracy'] for c in chunk_metrics])
        avg_chunk_mae = np.mean([c['MAE'] for c in chunk_metrics])
        print(f"   üìà Average chunk direction accuracy: {avg_chunk_acc:.3f}")
        print(f"   üìà Average chunk MAE: {avg_chunk_mae:.3f}")

    print(f"\nüìÅ Files generated:")
    print(f"   üìÑ predictions_chunk_walkforward.csv - All predictions with chunk info")
    print(f"   üìÑ chunk_metrics.csv - Performance metrics per chunk")  
    print(f"   üìÑ overall_metrics_per_ticker.csv - Overall performance per ticker")

    return predictions_df, overall_metrics

# ------------------------------------------------------------------------------------
# 6) Hyperparameter Tuning ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chunk_size ‡πÅ‡∏•‡∏∞‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ
# ------------------------------------------------------------------------------------

def hyperparameter_tuning_with_full_validation(
    model_template,
    df,
    feature_columns,
    ticker_scalers,
    ticker_encoder,
    market_encoder,
    param_grid,
    validation_split=0.2,
    max_trials=10
):
    """
    ‡∏ó‡∏≥ Hyperparameter Tuning ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á chunk_size ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Grid Search
    
    Parameters:
    -----------
    model_template : callable
        ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
    df : DataFrame
        ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    feature_columns : list
        ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ features
    ticker_scalers : dict
        Scalers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ ticker
    ticker_encoder : LabelEncoder
        Encoder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ticker
    market_encoder : LabelEncoder  
        Encoder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö market
    param_grid : dict
        Grid ‡∏Ç‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    validation_split : float
        ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö validation
    max_trials : int
        ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        
    Returns:
    --------
    dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ tuning
    """
    
    print("üîç Starting Hyperparameter Tuning with chunk_size optimization...")
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö validation
    val_size = int(len(df) * validation_split)
    train_tuning_df = df.iloc[:-val_size].copy()
    val_tuning_df = df.iloc[-val_size:].copy()
    
    print(f"üìä Data split: Train={len(train_tuning_df)}, Validation={len(val_tuning_df)}")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á parameter combinations
    param_names = list(param_grid.keys())
    param_values = list(param_grid.values())
    
    from itertools import product
    param_combinations = list(product(*param_values))[:max_trials]
    
    print(f"üéØ Testing {len(param_combinations)} parameter combinations...")
    
    results = []
    best_score = float('inf')
    best_params = None
    
    for trial_idx, param_combo in enumerate(param_combinations):
        params = dict(zip(param_names, param_combo))
        
        print(f"\nüî¨ Trial {trial_idx + 1}/{len(param_combinations)}")
        print(f"   Parameters: {params}")
        
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
            test_model = model_template(**params)
            
            # ‡∏ó‡∏≥ Full Validation ‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏´‡∏∏‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ walk_forward_validation_multi_task_batch
            val_predictions, val_results = full_model_validation(
                model=test_model,
                val_df=val_tuning_df,
                feature_columns=feature_columns,
                ticker_scalers=ticker_scalers,
                ticker_encoder=ticker_encoder,
                market_encoder=market_encoder,
                chunk_size=params.get('chunk_size', 200),
                seq_length=params.get('seq_length', 10),
                retrain_frequency=params.get('retrain_frequency', 5)
            )
            
            # ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å overall metrics
            overall_metrics = val_results.get('overall_metrics', {})
            comprehensive_score = overall_metrics.get('comprehensive_score', float('inf'))
            weighted_mae = overall_metrics.get('weighted_mae', float('inf'))
            weighted_acc = overall_metrics.get('weighted_direction_accuracy', 0)
            ticker_coverage = overall_metrics.get('ticker_coverage', 0)
            total_predictions = overall_metrics.get('total_predictions', 0)
            num_tickers = overall_metrics.get('num_tickers_predicted', 0)
            
            result = {
                'trial': trial_idx + 1,
                'params': params,
                'weighted_mae': weighted_mae,
                'weighted_direction_accuracy': weighted_acc,
                'ticker_coverage': ticker_coverage,
                'comprehensive_score': comprehensive_score,
                'total_predictions': total_predictions,
                'num_tickers_predicted': num_tickers,
                'individual_results': val_results.get('individual_metrics', {})
            }
            
            results.append(result)
            
            print(f"   üìà Results: MAE={weighted_mae:.4f}, Dir_Acc={weighted_acc:.4f}")
            print(f"       Ticker Coverage: {ticker_coverage:.2%}, Comprehensive Score: {comprehensive_score:.4f}")
            
            # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï best parameters (‡πÉ‡∏ä‡πâ comprehensive score)
            if comprehensive_score < best_score:
                best_score = comprehensive_score
                best_params = params.copy()
                print(f"   üéØ New best comprehensive score: {comprehensive_score:.4f}")
                print(f"       Best coverage: {ticker_coverage:.2%} ({num_tickers}/{len(val_tuning_df['Ticker'].unique())} tickers)")
                
        except Exception as e:
            print(f"   ‚ùå Trial failed: {e}")
            result = {
                'trial': trial_idx + 1,
                'params': params,
                'weighted_mae': float('inf'),
                'weighted_direction_accuracy': 0,
                'ticker_coverage': 0,
                'comprehensive_score': float('inf'),
                'total_predictions': 0,
                'num_tickers_predicted': 0,
                'error': str(e)
            }
            results.append(result)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    results_df = pd.DataFrame(results)
    results_df.to_csv('hyperparameter_tuning_results.csv', index=False)
    
    print(f"\nüèÜ Hyperparameter Tuning Complete!")
    print(f"   Best Parameters: {best_params}")
    print(f"   Best Combined Score: {best_score:.4f}")
    print(f"   üíæ Results saved to 'hyperparameter_tuning_results.csv'")
    
    return {
        'best_params': best_params,
        'best_score': best_score,
        'all_results': results,
        'results_df': results_df
    }

def full_model_validation(model, val_df, feature_columns, ticker_scalers, 
                         ticker_encoder, market_encoder, chunk_size=200, 
                         seq_length=10, retrain_frequency=5):
    """
    ‡∏ó‡∏≥ Full Validation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ walk_forward_validation_multi_task_batch
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏´‡∏∏‡πâ‡∏ô‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• validation
    """
    try:
        print(f"   üîç Running full validation with all {len(val_df['Ticker'].unique())} tickers...")
        
        # ‡πÉ‡∏ä‡πâ walk_forward_validation ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
        predictions, metrics = walk_forward_validation_multi_task_batch(
            model=model,
            df=val_df,
            feature_columns=feature_columns,
            ticker_scalers=ticker_scalers,
            ticker_encoder=ticker_encoder,
            market_encoder=market_encoder,
            seq_length=seq_length,
            retrain_frequency=retrain_frequency,
            chunk_size=chunk_size
        )
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì overall metrics across all tickers
        if metrics and len(metrics) > 0:
            all_maes = [m['MAE'] for m in metrics.values()]
            all_accs = [m['Direction_Accuracy'] for m in metrics.values()]
            all_r2s = [m['R2_Score'] for m in metrics.values()]
            all_predictions = [m['Total_Predictions'] for m in metrics.values()]
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weighted average (‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô predictions)
            total_predictions = sum(all_predictions)
            if total_predictions > 0:
                weighted_mae = sum(mae * pred for mae, pred in zip(all_maes, all_predictions)) / total_predictions
                weighted_acc = sum(acc * pred for acc, pred in zip(all_accs, all_predictions)) / total_predictions
                weighted_r2 = sum(r2 * pred for r2, pred in zip(all_r2s, all_predictions)) / total_predictions
            else:
                weighted_mae = np.mean(all_maes) if all_maes else float('inf')
                weighted_acc = np.mean(all_accs) if all_accs else 0
                weighted_r2 = np.mean(all_r2s) if all_r2s else -1
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì comprehensive score
            # ‡πÉ‡∏ä‡πâ weighted metrics ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å‡∏´‡∏∏‡πâ‡∏ô
            ticker_coverage = len(metrics) / len(val_df['Ticker'].unique())  # ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ
            coverage_bonus = ticker_coverage * 0.5  # bonus ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å
            
            comprehensive_score = (weighted_mae * 2.0 + 
                                 (1 - weighted_acc) * 1.5 + 
                                 max(0, -weighted_r2) * 0.5 - 
                                 coverage_bonus)
            
            return predictions, {
                'individual_metrics': metrics,
                'overall_metrics': {
                    'weighted_mae': weighted_mae,
                    'weighted_direction_accuracy': weighted_acc,
                    'weighted_r2_score': weighted_r2,
                    'ticker_coverage': ticker_coverage,
                    'total_predictions': total_predictions,
                    'comprehensive_score': comprehensive_score,
                    'num_tickers_predicted': len(metrics)
                }
            }
        else:
            return predictions, {
                'individual_metrics': {},
                'overall_metrics': {
                    'weighted_mae': float('inf'),
                    'weighted_direction_accuracy': 0,
                    'weighted_r2_score': -1,
                    'ticker_coverage': 0,
                    'total_predictions': 0,
                    'comprehensive_score': float('inf'),
                    'num_tickers_predicted': 0
                }
            }
        
    except Exception as e:
        print(f"   ‚ùå Full validation error: {e}")
        return None, {
            'individual_metrics': {},
            'overall_metrics': {
                'weighted_mae': float('inf'),
                'weighted_direction_accuracy': 0,
                'weighted_r2_score': -1,
                'ticker_coverage': 0,
                'total_predictions': 0,
                'comprehensive_score': float('inf'),
                'num_tickers_predicted': 0,
                'error': str(e)
            }
        }

def create_model_template(**kwargs):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö hyperparameter tuning
    """
    # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ hyperparameters
    embedding_dim = kwargs.get('embedding_dim', 33)
    LSTM_units_1 = kwargs.get('LSTM_units_1', 65)
    LSTM_units_2 = kwargs.get('LSTM_units_2', 32)
    dropout_rate = kwargs.get('dropout_rate', 0.21)
    dense_units = kwargs.get('dense_units', 66)
    learning_rate = kwargs.get('learning_rate', 1.7e-4)
    batch_size = kwargs.get('batch_size', 33)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏°
    features_input = Input(shape=(seq_length, num_feature), name='features_input')
    ticker_input = Input(shape=(seq_length,), name='ticker_input')
    market_input = Input(shape=(seq_length,), name='market_input')

    # Ticker Embedding
    ticker_embedding = Embedding(
        input_dim=num_tickers,
        output_dim=embedding_dim,
        embeddings_regularizer=tf.keras.regularizers.l2(1e-7),
        name="ticker_embedding"
    )(ticker_input)
    ticker_embedding = Dense(16, activation="relu")(ticker_embedding)

    # Market Embedding
    market_embedding = Embedding(
        input_dim=num_markets,
        output_dim=8,
        embeddings_regularizer=tf.keras.regularizers.l2(1e-7),
        name="market_embedding"
    )(market_input)
    market_embedding = Dense(8, activation="relu")(market_embedding)

    # Merge inputs
    merged = concatenate([features_input, ticker_embedding, market_embedding], axis=-1)

    # LSTM layers
    x = Bidirectional(LSTM(LSTM_units_1, return_sequences=True, dropout=dropout_rate, recurrent_dropout=0.15))(merged)
    x = Dropout(dropout_rate)(x)
    x = Bidirectional(LSTM(LSTM_units_2, return_sequences=False, dropout=dropout_rate, recurrent_dropout=0.15))(x)
    x = Dropout(dropout_rate)(x)

    # Shared representation
    shared_repr = Dense(dense_units, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(1e-6))(x)

    # Output heads
    price_head = Dense(32, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(1e-6))(shared_repr)
    price_head = Dropout(0.22)(price_head)
    price_output = Dense(1, name="price_output")(price_head)

    dir_head = Dense(32, activation="relu", kernel_regularizer=tf.keras.regularizers.l2(1e-6))(shared_repr)
    dir_head = Dropout(0.22)(dir_head)
    direction_output = Dense(1, activation="sigmoid", name="direction_output")(dir_head)

    # Create and compile model
    model = Model(
        inputs=[features_input, ticker_input, market_input],
        outputs=[price_output, direction_output]
    )
    
    # Optimizer
    lr_schedule = CosineDecay(
        initial_learning_rate=learning_rate,
        decay_steps=1000,
        alpha=9e-6
    )
    
    optimizer = AdamW(
        learning_rate=lr_schedule,
        weight_decay=1.4e-5,
        clipnorm=0.95
    )
    
    # Compile
    model.compile(
        optimizer=optimizer,
        loss={
            "price_output": tf.keras.losses.Huber(delta=0.75),
            "direction_output": focal_weighted_binary_crossentropy(class_weight_dict, gamma=1.95)
        },
        loss_weights={"price_output": 0.39, "direction_output": 0.61},
        metrics={
            "price_output": [tf.keras.metrics.MeanAbsoluteError()],
            "direction_output": [tf.keras.metrics.BinaryAccuracy()]
        }
    )
    
    return model

# Grid Search Parameters
param_grid = {
    'chunk_size': [100, 150, 200, 250, 300],
    'embedding_dim': [24, 33, 48],
    'LSTM_units_1': [48, 65, 80],
    'LSTM_units_2': [24, 32, 48],
    'dropout_rate': [0.15, 0.21, 0.28],
    'dense_units': [48, 66, 80],
    'learning_rate': [1.2e-4, 1.7e-4, 2.2e-4],
    'retrain_frequency': [3, 5, 7],
    'seq_length': [10]
}

# ‡∏ó‡∏≥ Hyperparameter Tuning with Full Validation
print("üöÄ Starting comprehensive hyperparameter tuning with full walk-forward validation...")
print("üìä Each model will be tested on ALL tickers using walk_forward_validation_multi_task_batch")
tuning_results = hyperparameter_tuning_with_full_validation(
    model_template=create_model_template,
    df=test_df,
    feature_columns=feature_columns,
    ticker_scalers=ticker_scalers,
    ticker_encoder=ticker_encoder,
    market_encoder=market_encoder,
    param_grid=param_grid,
    validation_split=0.2,
    max_trials=15
)

# ‡πÉ‡∏ä‡πâ best parameters ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ training final model
best_params = tuning_results['best_params']
print(f"\nüéØ Using best parameters for final evaluation: {best_params}")

# ------------------------------------------------------------------------------------
# 7) ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Walk-Forward Validation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Multi-Task ‡∏î‡πâ‡∏ß‡∏¢ Best Parameters
# ------------------------------------------------------------------------------------

predictions_df, results_per_ticker = walk_forward_validation_multi_task_batch(
    model = best_model,
    df = test_df,
    feature_columns = feature_columns,
    ticker_scalers = ticker_scalers,  
    ticker_encoder = ticker_encoder,
    market_encoder = market_encoder,
    seq_length = best_params.get('seq_length', 10),
    retrain_frequency = best_params.get('retrain_frequency', 5),
    chunk_size = best_params.get('chunk_size', 200)
)

for ticker, metrics in results_per_ticker.items():
    print(f"\nMetrics for {ticker}:")
    print(f"  MAE:  {metrics['MAE']:.4f}")
    print(f"  MSE:  {metrics['MSE']:.4f}")
    print(f"  RMSE: {metrics['RMSE']:.4f}")
    print(f"  MAPE: {metrics['MAPE']:.4f}")
    print(f"  SMAPE:{metrics['SMAPE']:.4f}")
    print(f"  R2 Score: {metrics['R2_Score']:.4f}")
    print(f"  Direction Accuracy: {metrics['Direction_Accuracy']:.4f}")
    print(f"  Direction F1 Score: {metrics['Direction_F1_Score']:.4f}")
    print(f"  Direction Precision: {metrics['Direction_Precision']:.4f}")
    print(f"  Direction Recall: {metrics['Direction_Recall']:.4f}")

metrics_df = pd.DataFrame.from_dict(results_per_ticker, orient='index')
metrics_df.to_csv('metrics_per_ticker_multi_task.csv', index=True)
print("\nSaved metrics per ticker to 'metrics_per_ticker_multi_task.csv'")

all_data = []
for ticker, group in predictions_df.groupby('Ticker'):
    for idx, row in group.iterrows():
        date_val = row['Date']
        actual_p = row['Actual_Price']
        pred_p   = row['Predicted_Price']
        actual_d = row['Actual_Dir']
        pred_d   = row['Predicted_Dir']
        
        all_data.append([ticker, date_val, actual_p, pred_p, actual_d, pred_d])

# ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
prediction_df = pd.DataFrame(all_data, columns=[
    'Ticker','Date','Actual_Price','Predicted_Price','Actual_Dir','Predicted_Dir',
])
prediction_df.to_csv('all_predictions_per_day_multi_task.csv', index=False)
print("Saved actual and predicted (price & direction) to 'all_predictions_per_day_multi_task.csv'")

# ------------------------------------------------------------------------------------
# 8) ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£ Hyperparameter Tuning ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£ Evaluation
# ------------------------------------------------------------------------------------

def generate_comprehensive_report(tuning_results, predictions_df, results_per_ticker, best_params):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°
    """
    
    print("\n" + "="*80)
    print("üìä COMPREHENSIVE HYPERPARAMETER TUNING REPORT")
    print("="*80)
    
    # 1. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£ Hyperparameter Tuning
    print("\nüîç HYPERPARAMETER TUNING SUMMARY:")
    print("-" * 50)
    
    if tuning_results and 'results_df' in tuning_results:
        results_df = tuning_results['results_df']
        
        # ‡πÅ‡∏™‡∏î‡∏á top 5 combinations
        if len(results_df) > 0:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° comprehensive_score (‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤)
            top_results = results_df.nsmallest(5, 'comprehensive_score')
            
            print("üèÜ TOP 5 PARAMETER COMBINATIONS (Full Walk-Forward Validation):")
            for idx, (_, row) in enumerate(top_results.iterrows(), 1):
                print(f"\n   #{idx} - Comprehensive Score: {row['comprehensive_score']:.4f}")
                print(f"        Weighted MAE: {row['weighted_mae']:.4f} | Weighted Dir Acc: {row['weighted_direction_accuracy']:.4f}")
                print(f"        Ticker Coverage: {row['ticker_coverage']:.2%} ({row['num_tickers_predicted']} tickers)")
                print(f"        Total Predictions: {row['total_predictions']}")
                if 'params' in row and row['params']:
                    params = eval(str(row['params'])) if isinstance(row['params'], str) else row['params']
                    print(f"        chunk_size: {params.get('chunk_size', 'N/A')}")
                    print(f"        learning_rate: {params.get('learning_rate', 'N/A')}")
                    print(f"        LSTM_units_1: {params.get('LSTM_units_1', 'N/A')}")
                    print(f"        dropout_rate: {params.get('dropout_rate', 'N/A')}")
    
    # 2. Best Parameters Analysis
    print(f"\nüéØ OPTIMAL PARAMETERS FOUND:")
    print("-" * 50)
    if best_params:
        for param, value in best_params.items():
            print(f"   {param:.<20} {value}")
    
    # 3. Final Model Performance
    print(f"\nüìà FINAL MODEL PERFORMANCE:")
    print("-" * 50)
    
    if results_per_ticker:
        all_maes = [metrics['MAE'] for metrics in results_per_ticker.values()]
        all_accs = [metrics['Direction_Accuracy'] for metrics in results_per_ticker.values()]
        all_r2s = [metrics['R2_Score'] for metrics in results_per_ticker.values()]
        
        print(f"   Average MAE across all tickers: {np.mean(all_maes):.4f} ¬± {np.std(all_maes):.4f}")
        print(f"   Average Direction Accuracy: {np.mean(all_accs):.4f} ¬± {np.std(all_accs):.4f}")
        print(f"   Average R¬≤ Score: {np.mean(all_r2s):.4f} ¬± {np.std(all_r2s):.4f}")
        print(f"   Best MAE: {min(all_maes):.4f}")
        print(f"   Best Direction Accuracy: {max(all_accs):.4f}")
        print(f"   Best R¬≤ Score: {max(all_r2s):.4f}")
    
    # 4. Ticker-wise Detailed Performance
    print(f"\nüìä DETAILED PERFORMANCE BY TICKER:")
    print("-" * 50)
    
    if results_per_ticker:
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û (MAE)
        sorted_tickers = sorted(results_per_ticker.items(), key=lambda x: x[1]['MAE'])
        
        print(f"{'Ticker':<10} {'MAE':<8} {'Dir_Acc':<8} {'R¬≤':<8} {'Predictions':<12}")
        print("-" * 50)
        
        for ticker, metrics in sorted_tickers:
            mae = metrics['MAE']
            acc = metrics['Direction_Accuracy']
            r2 = metrics['R2_Score']
            preds = metrics['Total_Predictions']
            print(f"{ticker:<10} {mae:<8.4f} {acc:<8.4f} {r2:<8.4f} {preds:<12}")
    
    # 5. Chunk Size Analysis
    print(f"\nüì¶ CHUNK SIZE ANALYSIS:")
    print("-" * 50)
    
    if tuning_results and 'results_df' in tuning_results:
        results_df = tuning_results['results_df']
        
        if len(results_df) > 0:
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏≤‡∏° chunk_size
            chunk_analysis = {}
            
            for _, row in results_df.iterrows():
                if 'params' in row and row['params']:
                    try:
                        params = eval(str(row['params'])) if isinstance(row['params'], str) else row['params']
                        chunk_size = params.get('chunk_size', 200)
                        
                        if chunk_size not in chunk_analysis:
                            chunk_analysis[chunk_size] = []
                        
                        chunk_analysis[chunk_size].append({
                            'mae': row.get('weighted_mae', float('inf')),
                            'acc': row.get('weighted_direction_accuracy', 0),
                            'coverage': row.get('ticker_coverage', 0),
                            'score': row.get('comprehensive_score', float('inf'))
                        })
                    except:
                        continue
            
            if chunk_analysis:
                print(f"{'Chunk Size':<12} {'Avg W_MAE':<12} {'Avg W_Acc':<12} {'Avg Coverage':<12} {'Avg Score':<12} {'Trials':<8}")
                print("-" * 80)
                
                for chunk_size, trials in sorted(chunk_analysis.items()):
                    valid_trials = [t for t in trials if not np.isinf(t.get('mae', float('inf')))]
                    if valid_trials:
                        avg_mae = np.mean([t['mae'] for t in valid_trials])
                        avg_acc = np.mean([t['acc'] for t in valid_trials])
                        avg_coverage = np.mean([t.get('coverage', 0) for t in valid_trials])
                        avg_score = np.mean([t['score'] for t in valid_trials if not np.isinf(t['score'])])
                        num_trials = len(trials)
                        
                        print(f"{chunk_size:<12} {avg_mae:<12.4f} {avg_acc:<12.4f} {avg_coverage:<12.2%} {avg_score:<12.4f} {num_trials:<8}")
    
    # 6. Recommendations
    print(f"\nüí° RECOMMENDATIONS:")
    print("-" * 50)
    
    if best_params:
        optimal_chunk = best_params.get('chunk_size', 200)
        optimal_lr = best_params.get('learning_rate', 1.7e-4)
        optimal_dropout = best_params.get('dropout_rate', 0.21)
        
        print(f"   ‚úÖ Use chunk_size = {optimal_chunk} for optimal performance")
        print(f"   ‚úÖ Learning rate {optimal_lr:.2e} provides best convergence")
        print(f"   ‚úÖ Dropout rate {optimal_dropout} balances overfitting vs underfitting")
        
        if results_per_ticker:
            avg_mae = np.mean([metrics['MAE'] for metrics in results_per_ticker.values()])
            avg_acc = np.mean([metrics['Direction_Accuracy'] for metrics in results_per_ticker.values()])
            
            if avg_mae < 6.0:
                print(f"   üéØ Excellent price prediction accuracy (MAE < 6.0)")
            elif avg_mae < 8.0:
                print(f"   ‚úÖ Good price prediction accuracy (MAE < 8.0)")
            else:
                print(f"   ‚ö†Ô∏è Price prediction needs improvement (MAE > 8.0)")
                
            if avg_acc > 0.6:
                print(f"   üéØ Strong directional prediction (Accuracy > 60%)")
            elif avg_acc > 0.55:
                print(f"   ‚úÖ Acceptable directional prediction (Accuracy > 55%)")
            else:
                print(f"   ‚ö†Ô∏è Directional prediction needs improvement (Accuracy < 55%)")
    
    # 7. Files Generated
    print(f"\nüìÅ GENERATED FILES:")
    print("-" * 50)
    print("   üìÑ hyperparameter_tuning_results.csv - Detailed tuning results")
    print("   üìÑ all_predictions_per_day_multi_task.csv - Daily predictions")
    print("   üìÑ metrics_per_ticker_multi_task.csv - Ticker-wise metrics")
    print("   üìÑ predictions_chunk_walkforward.csv - Chunk-based predictions")
    print("   üìÑ overall_metrics_per_ticker.csv - Overall performance metrics")
    
    print("\n" + "="*80)
    print("üéâ HYPERPARAMETER TUNING ANALYSIS COMPLETE!")
    print("="*80)

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
generate_comprehensive_report(
    tuning_results=tuning_results,
    predictions_df=predictions_df,
    results_per_ticker=results_per_ticker,
    best_params=best_params
)

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Best Parameters ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
best_params_summary = {
    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'best_parameters': best_params,
    'performance_summary': {
        'avg_mae': np.mean([metrics['MAE'] for metrics in results_per_ticker.values()]) if results_per_ticker else None,
        'avg_direction_accuracy': np.mean([metrics['Direction_Accuracy'] for metrics in results_per_ticker.values()]) if results_per_ticker else None,
        'avg_r2_score': np.mean([metrics['R2_Score'] for metrics in results_per_ticker.values()]) if results_per_ticker else None,
        'total_tickers_evaluated': len(results_per_ticker) if results_per_ticker else 0,
        'total_predictions_made': len(predictions_df) if predictions_df is not None else 0
    },
    'tuning_summary': {
        'total_trials_completed': len(tuning_results['all_results']) if tuning_results and 'all_results' in tuning_results else 0,
        'best_combined_score': tuning_results['best_score'] if tuning_results and 'best_score' in tuning_results else None
    }
}

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON
import json
with open('best_hyperparameters_summary.json', 'w') as f:
    json.dump(best_params_summary, f, indent=2, default=str)

print("\nüíæ Saved best parameters summary to 'best_hyperparameters_summary.json'")

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Best Parameters ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Production
production_config = {
    'model_config': {
        'seq_length': best_params.get('seq_length', 10),
        'chunk_size': best_params.get('chunk_size', 200),
        'retrain_frequency': best_params.get('retrain_frequency', 5),
        'embedding_dim': best_params.get('embedding_dim', 33),
        'LSTM_units_1': best_params.get('LSTM_units_1', 65),
        'LSTM_units_2': best_params.get('LSTM_units_2', 32),
        'dropout_rate': best_params.get('dropout_rate', 0.21),
        'dense_units': best_params.get('dense_units', 66),
        'learning_rate': best_params.get('learning_rate', 1.7e-4)
    },
    'training_config': {
        'batch_size': 33,
        'validation_split': 0.12,
        'expected_epochs': 105,
        'early_stopping_patience': 20,
        'lr_scheduler_patience': 7
    },
    'performance_benchmarks': {
        'target_mae': 6.0,
        'target_direction_accuracy': 0.60,
        'minimum_r2_score': 0.0
    }
}

with open('production_model_config.json', 'w') as f:
    json.dump(production_config, f, indent=2)

print("üíæ Saved production-ready config to 'production_model_config.json'")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ tuning
if best_params and tuning_results:
    print(f"\nüèÜ Creating final optimized model with best parameters...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    best_final_model = create_model_template(**best_params)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    best_final_model.save('best_hypertuned_model.keras')
    print("üíæ Saved best hypertuned model to 'best_hypertuned_model.keras'")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    model_comparison = {
        'original_model_performance': {
            'note': 'Results from using best_model (pre-trained) with original parameters'
        },
        'hypertuned_model_performance': {
            'best_parameters': best_params,
            'comprehensive_score': tuning_results.get('best_score', None),
            'note': 'Results from hyperparameter tuning with full walk-forward validation'
        },
        'comparison_summary': {
            'tuning_method': 'Full walk-forward validation on all tickers',
            'optimization_target': 'Comprehensive score (weighted MAE + direction accuracy + ticker coverage)',
            'total_parameter_combinations_tested': len(tuning_results.get('all_results', [])),
            'validation_method': 'walk_forward_validation_multi_task_batch'
        }
    }
    
    with open('model_comparison_results.json', 'w') as f:
        json.dump(model_comparison, f, indent=2, default=str)
    
    print("üíæ Saved model comparison to 'model_comparison_results.json'")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    print(f"\nüìã FINAL SUMMARY:")
    print(f"   üéØ Best chunk_size found: {best_params.get('chunk_size', 'N/A')}")
    print(f"   üß† Best LSTM architecture: {best_params.get('LSTM_units_1', 'N/A')}-{best_params.get('LSTM_units_2', 'N/A')} units")
    print(f"   üìö Best sequence length: {best_params.get('seq_length', 'N/A')}")
    print(f"   üîÑ Best retrain frequency: {best_params.get('retrain_frequency', 'N/A')}")
    print(f"   üìà Best learning rate: {best_params.get('learning_rate', 'N/A'):.2e}")
    
    if 'results_df' in tuning_results:
        best_result = tuning_results['results_df'].loc[tuning_results['results_df']['comprehensive_score'].idxmin()]
        print(f"\nüèÜ BEST MODEL PERFORMANCE ON ALL TICKERS:")
        print(f"   Weighted MAE: {best_result['weighted_mae']:.4f}")
        print(f"   Weighted Direction Accuracy: {best_result['weighted_direction_accuracy']:.4f}")
        print(f"   Ticker Coverage: {best_result['ticker_coverage']:.2%}")
        print(f"   Total Predictions Made: {best_result['total_predictions']}")
        print(f"   Tickers Successfully Predicted: {best_result['num_tickers_predicted']}")

print("\nüéØ Hyperparameter tuning and evaluation process completed successfully!")
print("üìÅ All results saved - ready for production deployment!")
