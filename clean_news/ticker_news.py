import spacy
from spacy.tokens import Span
import pandas as pd
from tqdm import tqdm
import time

# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ GPU
import spacy
if not spacy.prefer_gpu():
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GPU ‡∏´‡∏£‡∏∑‡∏≠ spaCy ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GPU")
else:
    print("üöÄ ‡πÉ‡∏ä‡πâ GPU:", spacy.prefer_gpu())

# ‚úÖ ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
stock_entities = {
    "AAPL": ["Apple"],
    "AMD": ["AMD", "Advanced Micro Devices"],
    "AMZN": ["Amazon"],
    "AVGO": ["Broadcom"],
    "GOOGL": ["Google", "Alphabet"],
    "META": ["Meta", "Facebook"],
    "MSFT": ["Microsoft"],
    "NVDA": ["Nvidia"],
    "TSLA": ["Tesla"],
    "TSM": ["TSMC", "Taiwan Semiconductor"]
}

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î spaCy Transformer Model
nlp = spacy.load("en_core_web_trf")
print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Entity Ruler
ruler = nlp.add_pipe("entity_ruler", before="ner")

patterns = []
for stock, keywords in stock_entities.items():
    for keyword in keywords:
        patterns.append({
            "label": "ORG",
            "pattern": keyword,
            "id": stock
        })

ruler.add_patterns(patterns)

# ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πà‡∏≤‡∏ß
file_path = "Combined_News.csv"
df = pd.read_csv(file_path)

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô NER
def extract_entities(row):
    text = f"{row.get('title', '')} {row.get('description', '')}"
    doc = nlp(text)
    matched = set()
    for ent in doc.ents:
        if ent.label_ == "ORG" and ent.ent_id_:
            matched.add(ent.ent_id_)
    return ", ".join(sorted(matched)) if matched else None

# ‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
start_time = time.time()

tqdm.pandas(desc="üîç NER Processing")
df["NER_MatchedStock"] = df.progress_apply(extract_entities, axis=1)

end_time = time.time()
elapsed = end_time - start_time

# ‚úÖ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
total_news = len(df)
related_df = df[df["NER_MatchedStock"].notnull()]
unrelated_df = df[df["NER_MatchedStock"].isnull()]
related_news = len(related_df)
unrelated_news = len(unrelated_df)
percentage = (related_news / total_news) * 100

print("\nüìä NER Model Summary")
print(f"‚úÖ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_news}")
print(f"‚úÖ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {related_news} ({percentage:.2f}%)")
print(f"‚úÖ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {unrelated_news} ({100 - percentage:.2f}%)")
print(f"‚è±Ô∏è ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {elapsed / 60:.2f} ‡∏ô‡∏≤‡∏ó‡∏µ\n")

# ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
related_df.to_csv("Related_News_NER.csv", index=False, encoding='utf-8')
unrelated_df.to_csv("Unrelated_News_NER.csv", index=False, encoding='utf-8')

print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà: Related_News_NER.csv")
print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà: Unrelated_News_NER.csv")
