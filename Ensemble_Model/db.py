# -*- coding: utf-8 -*-
import os
from pathlib import Path
from dotenv import load_dotenv
import pandas as pd
from sqlalchemy import create_engine, text

# ---------- .env ----------
# ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå: <root> / Ensemble_Model / (‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ)
# ‡πÅ‡∏•‡∏∞‡∏°‡∏µ <root>/Preproces/config.env
ROOT = Path(__file__).resolve().parents[1]
dotenv_path = ROOT / 'Preproces' / 'config.env'
load_dotenv(dotenv_path)

# ---------- DB URL ----------
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "3306")
DB_NAME = os.getenv("DB_NAME")

if not all([DB_USER, DB_PASSWORD, DB_HOST, DB_NAME]):
    raise RuntimeError("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ .env: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ DB_USER, DB_PASSWORD, DB_HOST, DB_NAME (‡πÅ‡∏•‡∏∞ DB_PORT ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)")

DB_CONNECTION = (
    f"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    f"?charset=utf8mb4"
)

# ---------- Engine ----------
def get_engine():
    # pool_pre_ping: ‡∏Å‡∏±‡∏ô connection ‡∏ï‡∏≤‡∏¢
    # pool_recycle: ‡∏£‡∏µ‡πÑ‡∏ã‡πÄ‡∏Ñ‡∏¥‡∏•‡∏ó‡∏∏‡∏Å 1 ‡∏ä‡∏°.
    return create_engine(
        DB_CONNECTION,
        pool_pre_ping=True,
        pool_recycle=3600,
        future=True,
    )

# ---------- Helpers ----------
def _pick_col(df, candidates, required=True):
    for c in candidates:
        if c in df.columns:
            return c
    if required:
        raise KeyError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏î‡πÜ ‡πÉ‡∏ô‡∏ä‡∏∏‡∏î: {candidates}")
    return None

def _to_date_str(series):
    # ‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á string ‡πÅ‡∏•‡∏∞ datetime ‚Üí ‡∏Ñ‡∏∑‡∏ô 'YYYY-MM-DD'
    s = pd.to_datetime(series, errors='coerce')
    return s.dt.strftime('%Y-%m-%d')

def _to_nullable_float(v):
    try:
        if pd.isna(v):
            return None
        return float(v)
    except Exception:
        return None

def load_predictions(file_path: str) -> pd.DataFrame:
    df = pd.read_csv(file_path)
    # strip ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡∏±‡∏ô‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ‡∏´‡∏•‡∏á‡∏°‡∏≤
    df.columns = df.columns.str.strip()
    return df

def save_predictions_to_db(pred_df: pd.DataFrame, batch_size: int = 1000):
    """
    ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢):
      - Ticker / ‡∏´‡∏£‡∏∑‡∏≠ StockSymbol
      - Date
      - Meta_Predicted_Price ‡∏´‡∏£‡∏∑‡∏≠ XGB_Predicted_Price
      - LSTM_Predicted_Price
      - GRU_Predicted_Price
    ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á stockdetail: PredictionClose_LSTM, PredictionClose_GRU, PredictionClose_Ensemble
    ‡πÉ‡∏ä‡πâ ON DUPLICATE KEY UPDATE (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ unique key (StockSymbol, date))
    """
    # ‡πÅ‡∏°‡∏û‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏ä‡∏∑‡πà‡∏≠)
    col_symbol = _pick_col(pred_df, ["Ticker", "StockSymbol"])
    col_date   = _pick_col(pred_df, ["Date"])
    col_meta   = _pick_col(pred_df, ["Meta_Predicted_Price", "XGB_Predicted_Price", "PredictionClose_Ensemble"])
    col_lstm   = _pick_col(pred_df, ["LSTM_Predicted_Price", "Predicted_Price_LSTM", "PredictionClose_LSTM"])
    col_gru    = _pick_col(pred_df, ["GRU_Predicted_Price", "Predicted_Price_GRU", "PredictionClose_GRU"])

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df = pred_df.copy()
    df["_date_str"] = _to_date_str(df[col_date])

    # records ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö executemany
    records = []
    for _, row in df.iterrows():
        records.append({
            "symbol": str(row[col_symbol]),
            "date":   row["_date_str"],
            "lstm":   _to_nullable_float(row[col_lstm]),
            "gru":    _to_nullable_float(row[col_gru]),
            "meta":   _to_nullable_float(row[col_meta]),
        })

    # ‡∏•‡∏ö‡πÄ‡∏£‡∏Ñ‡∏≠‡∏£‡πå‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ symbol ‡∏´‡∏£‡∏∑‡∏≠ date
    records = [r for r in records if r["symbol"] and r["date"]]

    if not records:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏£‡∏Ñ‡∏≠‡∏£‡πå‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï")
        return

    sql = text("""
        INSERT INTO stockdetail (`StockSymbol`, `date`, `PredictionClose_LSTM`, `PredictionClose_GRU`, `PredictionClose_Ensemble`)
        VALUES (:symbol, :date, :lstm, :gru, :meta)
        AS new
        ON DUPLICATE KEY UPDATE
            `PredictionClose_LSTM` = new.`PredictionClose_LSTM`,
            `PredictionClose_GRU` = new.`PredictionClose_GRU`,
            `PredictionClose_Ensemble` = new.`PredictionClose_Ensemble`;
    """)

    engine = get_engine()
    inserted = 0
    with engine.begin() as conn:
        # ‡πÅ‡∏ö‡πà‡∏á batch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        for i in range(0, len(records), batch_size):
            chunk = records[i:i+batch_size]
            conn.execute(sql, chunk)
            inserted += len(chunk)

    print(f"‚úÖ upsert ‡πÄ‡∏™‡∏£‡πá‡∏à: {inserted} rows ‚Üí stockdetail (PredictionClose_*).")

# ---------- main ----------
if __name__ == "__main__":
    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å XGB meta
    file_path = "./meta_price_predictions.csv"   # ‡πÄ‡∏î‡∏¥‡∏°‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ ensemble_predictions.csv
    if not Path(file_path).exists():
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå: {file_path}")

    df_pred = load_predictions(file_path)
    print(f"üìÑ {file_path} columns = {list(df_pred.columns)}")
    save_predictions_to_db(df_pred)
